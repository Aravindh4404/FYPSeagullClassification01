{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHQTt4Qh0nqhTl7pvaA2Fu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/remove_duplicate_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO7xbfj0EDS8",
        "outputId": "96f79dda-025a-417f-a022-e10a53cd9cbb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, imagehash\n",
            "Successfully installed PyWavelets-1.7.0 imagehash-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3YSG6hEDALd",
        "outputId": "05080b61-049d-41f6-94b2-9e4b9a629406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "No duplicates found.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import imagehash\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define paths to train and test folders in Google Drive\n",
        "train_folder = '/content/drive/My Drive/FYP/Dataset/HQSBNGW/train/Glaucous_Winged_Gull'\n",
        "test_folder = '/content/drive/My Drive/FYP/Dataset/HQSBNGW/test/Glaucous_Winged_Gull'\n",
        "\n",
        "# Function to calculate hash for each image in the folder\n",
        "def get_image_hashes(folder_path):\n",
        "    \"\"\"Calculate hash for each image in the folder and return a dictionary with file paths.\"\"\"\n",
        "    image_hashes = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            # Open and convert image to RGB\n",
        "            image = Image.open(file_path).convert(\"RGB\")\n",
        "            # Get perceptual hash\n",
        "            hash_value = imagehash.average_hash(image)\n",
        "            image_hashes[file_path] = hash_value\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "    return image_hashes\n",
        "\n",
        "# Function to find and delete duplicate images in the test folder\n",
        "def delete_duplicates(train_folder, test_folder):\n",
        "    train_hashes = get_image_hashes(train_folder)\n",
        "    test_hashes = get_image_hashes(test_folder)\n",
        "\n",
        "    duplicates = []\n",
        "    for test_path, test_hash in test_hashes.items():\n",
        "        # Check if the hash from the test folder matches any in the train folder\n",
        "        if test_hash in train_hashes.values():\n",
        "            duplicates.append(test_path)\n",
        "            # Delete the duplicate image from the test folder\n",
        "            try:\n",
        "                os.remove(test_path)\n",
        "                print(f\"Deleted duplicate image: {test_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {test_path}: {e}\")\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Step 3: Find and delete duplicates\n",
        "duplicates = delete_duplicates(train_folder, test_folder)\n",
        "if duplicates:\n",
        "    print(\"Duplicates deleted from the test folder.\")\n",
        "else:\n",
        "    print(\"No duplicates found.\")"
      ]
    }
  ]
}