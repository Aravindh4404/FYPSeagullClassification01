{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOf26s+tMK+JZOxut6CYZ4F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/LATESTVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The latest model train below That is /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth is not that good regarding the interpretability and the prediction number of images compared to original vgg model"
      ],
      "metadata": {
        "id": "E7CqED52LlTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_XYumkRVh-L",
        "outputId": "6707f50d-6e84-4a48-d1d1-04af985a34dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from collections import Counter\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Define the device for computation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "data_path = '/content/drive/My Drive/FYP/Dataset/HQ3/train'\n",
        "test_data_path = '/content/drive/My Drive/FYP/Dataset/HQ3/test'\n",
        "checkpoint_folder = f'/content/drive/My Drive/FYP/VGGModel/HQ3Optuna_{datetime.now().strftime(\"%Y%m%d\")}/'\n",
        "os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "# Fixed checkpoint file path\n",
        "checkpoint_file = os.path.join(checkpoint_folder, 'latest_checkpoint.pth')\n",
        "\n",
        "# Calculate class weights\n",
        "original_train_dataset = datasets.ImageFolder(data_path)\n",
        "targets = [s[1] for s in original_train_dataset.samples]\n",
        "class_counts = Counter(targets)\n",
        "total = sum(class_counts.values())\n",
        "class_weights = torch.tensor([\n",
        "    total/(2*class_counts[0]),  # Smaller class\n",
        "    total/(2*class_counts[1])   # Larger class\n",
        "]).float().to(device)\n",
        "\n",
        "# Data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.05, 0.05)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.95, 1.0)),\n",
        "    transforms.RandomAdjustSharpness(1.2, p=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create base dataset\n",
        "full_train_dataset = datasets.ImageFolder(data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(test_data_path, transform=transform_val_test)\n",
        "\n",
        "# Stratified train-val split\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42)\n",
        "train_indices, val_indices = next(sss.split(np.zeros(len(targets)), targets))\n",
        "train_dataset = Subset(full_train_dataset, train_indices)\n",
        "val_dataset = Subset(full_train_dataset, val_indices)\n",
        "\n",
        "# Modified VGG model with flexible classifier\n",
        "class VGG16Modified(nn.Module):\n",
        "    def __init__(self, dropout_rate, hidden_units):\n",
        "        super().__init__()\n",
        "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.vgg.classifier[6].in_features\n",
        "\n",
        "        # Build custom classifier\n",
        "        classifier_layers = []\n",
        "        for units in hidden_units:\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(num_ftrs, units),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ])\n",
        "            num_ftrs = units\n",
        "        classifier_layers.append(nn.Linear(num_ftrs, 2))\n",
        "\n",
        "        self.vgg.classifier[6] = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, checkpoint_file):\n",
        "    \"\"\"Save model checkpoint.\"\"\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_file)\n",
        "    print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_file}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_file):\n",
        "    \"\"\"Load model checkpoint.\"\"\"\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        checkpoint = torch.load(checkpoint_file)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        return start_epoch\n",
        "    return 0\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, scheduler, epochs):\n",
        "    \"\"\"Training loop with checkpointing.\"\"\"\n",
        "    start_epoch = load_checkpoint(model, optimizer, checkpoint_file)\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = nn.CrossEntropyLoss(weight=class_weights)(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                correct += (model(inputs).argmax(1) == labels).sum().item()\n",
        "        val_acc = 100 * correct / len(val_dataset)\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Save checkpoint after each epoch\n",
        "        save_checkpoint(model, optimizer, epoch, checkpoint_file)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# Final training function\n",
        "def full_train(model, optimizer, scheduler, epochs=50):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    train(model, train_loader, val_loader, optimizer, scheduler, epochs)\n",
        "\n",
        "# Load best parameters from Optuna study\n",
        "best_params = {\n",
        "    'lr': 0.0001,\n",
        "    'weight_decay': 0.001,\n",
        "    'dropout_rate': 0.5,\n",
        "    'hidden_units': [512],\n",
        "    'optimizer': 'AdamW',\n",
        "    'batch_size': 16,\n",
        "    'grad_clip': 2.0,\n",
        "    'sched_factor': 0.1,\n",
        "    'sched_patience': 3\n",
        "}\n",
        "\n",
        "# Initialize final model\n",
        "final_model = VGG16Modified(\n",
        "    dropout_rate=best_params['dropout_rate'],\n",
        "    hidden_units=best_params.get('hidden_units', [])\n",
        ").to(device)\n",
        "\n",
        "# Initialize optimizer and scheduler\n",
        "optimizer = optim.AdamW(final_model.parameters(),\n",
        "                       lr=best_params['lr'],\n",
        "                       weight_decay=best_params['weight_decay'])\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=best_params['sched_factor'],\n",
        "    patience=best_params['sched_patience']\n",
        ")\n",
        "\n",
        "# Execute final training\n",
        "full_train(final_model, optimizer, scheduler, epochs=50)\n",
        "\n",
        "# Test evaluation\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            correct += (model(inputs).argmax(1) == labels).sum().item()\n",
        "    print(f\"Test Accuracy: {100 * correct / len(test_dataset):.2f}%\")\n",
        "\n",
        "test(final_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyKjTI-uVsTz",
        "outputId": "d740b98f-85ce-4e36-e10e-f8dd94b06dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checkpoint saved at epoch 1 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [1/50] - Loss: 0.6334, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 2 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [2/50] - Loss: 0.7533, Val Acc: 86.84%\n",
            "Checkpoint saved at epoch 3 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [3/50] - Loss: 0.4721, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 4 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [4/50] - Loss: 0.2428, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 5 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [5/50] - Loss: 0.1502, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 6 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [6/50] - Loss: 0.1077, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 7 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [7/50] - Loss: 0.3596, Val Acc: 100.00%\n",
            "Checkpoint saved at epoch 8 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [8/50] - Loss: 0.1266, Val Acc: 89.47%\n",
            "Checkpoint saved at epoch 9 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [9/50] - Loss: 0.1257, Val Acc: 100.00%\n",
            "Checkpoint saved at epoch 10 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [10/50] - Loss: 0.1145, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 11 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [11/50] - Loss: 0.0286, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 12 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [12/50] - Loss: 0.0094, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 13 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [13/50] - Loss: 0.0059, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 14 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [14/50] - Loss: 0.0017, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 15 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [15/50] - Loss: 0.0006, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 16 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [16/50] - Loss: 0.0002, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 17 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [17/50] - Loss: 0.1397, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 18 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [18/50] - Loss: 0.0015, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 19 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [19/50] - Loss: 0.0030, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 20 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [20/50] - Loss: 0.0000, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 21 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [21/50] - Loss: 0.0001, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 22 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [22/50] - Loss: 0.0058, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 23 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [23/50] - Loss: 0.0001, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 24 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [24/50] - Loss: 0.0001, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 25 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [25/50] - Loss: 0.0010, Val Acc: 94.74%\n",
            "Checkpoint saved at epoch 26 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [26/50] - Loss: 0.0008, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 27 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [27/50] - Loss: 0.0008, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 28 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [28/50] - Loss: 0.0170, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 29 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [29/50] - Loss: 0.0000, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 30 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [30/50] - Loss: 0.0003, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 31 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [31/50] - Loss: 0.0001, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 32 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [32/50] - Loss: 0.0375, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 33 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [33/50] - Loss: 0.0058, Val Acc: 97.37%\n",
            "Checkpoint saved at epoch 34 to /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Epoch [34/50] - Loss: 0.0113, Val Acc: 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D7_TWL1YHSr",
        "outputId": "1fb5d2ce-8e5b-49cd-d4d1-ae6a16e10084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}