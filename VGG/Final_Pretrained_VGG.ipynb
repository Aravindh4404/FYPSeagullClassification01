{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfIFORo5Xfn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890e0095-3fb3-4f9d-9a96-422ec5c96ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 69.1MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with validation accuracy: 67.84%\n",
            "Epoch [1/30] - Train Loss: 0.388848, Val Loss: 0.845492, Val Acc: 67.84%, Val F1: 0.7638, Val ROC-AUC: 0.9564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-6bb455efa7bc>:222: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_df = pd.concat([metrics_df, pd.DataFrame({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with validation accuracy: 97.80%\n",
            "Epoch [2/30] - Train Loss: 0.140219, Val Loss: 0.049306, Val Acc: 97.80%, Val F1: 0.9867, Val ROC-AUC: 0.9997\n",
            "Epoch [3/30] - Train Loss: 0.113170, Val Loss: 0.180741, Val Acc: 95.15%, Val F1: 0.9704, Val ROC-AUC: 0.9939\n",
            "New best model saved with validation accuracy: 98.24%\n",
            "Epoch [4/30] - Train Loss: 0.021982, Val Loss: 0.056263, Val Acc: 98.24%, Val F1: 0.9895, Val ROC-AUC: 0.9980\n",
            "Epoch [5/30] - Train Loss: 0.053431, Val Loss: 0.032870, Val Acc: 98.24%, Val F1: 0.9894, Val ROC-AUC: 0.9997\n",
            "Epoch [6/30] - Train Loss: 0.061378, Val Loss: 0.152767, Val Acc: 97.80%, Val F1: 0.9871, Val ROC-AUC: 0.9843\n",
            "Epoch [7/30] - Train Loss: 0.000153, Val Loss: 0.246252, Val Acc: 97.36%, Val F1: 0.9840, Val ROC-AUC: 0.9983\n",
            "Epoch [8/30] - Train Loss: 0.019992, Val Loss: 0.300291, Val Acc: 96.48%, Val F1: 0.9786, Val ROC-AUC: 0.9951\n",
            "Epoch [9/30] - Train Loss: 0.005959, Val Loss: 0.052999, Val Acc: 98.24%, Val F1: 0.9895, Val ROC-AUC: 0.9983\n",
            "Epoch [10/30] - Train Loss: 0.000100, Val Loss: 0.054776, Val Acc: 98.24%, Val F1: 0.9895, Val ROC-AUC: 0.9983\n",
            "New best model saved with validation accuracy: 98.68%\n",
            "Epoch [11/30] - Train Loss: 0.000001, Val Loss: 0.060114, Val Acc: 98.68%, Val F1: 0.9921, Val ROC-AUC: 0.9983\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, average_precision_score, matthews_corrcoef, balanced_accuracy_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# Define the device for computation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Mount Google Drive to save and load the model (if using Google Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_path = '/content/drive/My Drive/FYP'\n",
        "except ImportError:\n",
        "    base_path = '.'  # Use current directory if not in Colab\n",
        "\n",
        "# Define the folder to save model checkpoints\n",
        "date_str = datetime.now().strftime('%Y%m%d')\n",
        "checkpoint_folder = f'{base_path}/VGGModel/HQ3latest_{date_str}/'\n",
        "os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "# Data Augmentation for Training Set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG expects 224x224 input size\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip left/right\n",
        "    transforms.RandomVerticalFlip(p=0.3),  # Flip up/down\n",
        "    transforms.RandomRotation(degrees=10),  # Small rotation\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # Slight shifts\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),  # Small color changes\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Simple resizing for validation and test sets\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "data_path = f'{base_path}/Dataset/HQ3/train'\n",
        "test_data_path = f'{base_path}/Dataset/HQ3/test'\n",
        "train_dataset = datasets.ImageFolder(data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(test_data_path, transform=transform_val_test)\n",
        "\n",
        "# Split the dataset into 95% training and 5% validation\n",
        "train_size = int(0.7 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Set validation set transformation explicitly\n",
        "val_dataset.dataset.transform = transform_val_test\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Use Pre-trained VGG-16 model and modify it for binary classification\n",
        "class VGG16Modified(nn.Module):\n",
        "    def __init__(self, num_classes=2, dropout_rate=0.4):\n",
        "        super(VGG16Modified, self).__init__()\n",
        "        from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "        # Load pre-trained VGG16 model\n",
        "        self.vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Replace the classifier with a custom classification layer\n",
        "        num_ftrs = self.vgg.classifier[6].in_features\n",
        "        self.vgg.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "# Initialize the VGG model\n",
        "model = VGG16Modified().to(device)\n",
        "\n",
        "# Define loss function and optimizer with L2 regularization (weight decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_scores):\n",
        "    \"\"\"Calculate various classification metrics.\"\"\"\n",
        "    metrics = {}\n",
        "    metrics['accuracy'] = accuracy_score(y_true, y_pred) * 100\n",
        "    metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
        "    metrics['precision'] = precision_score(y_true, y_pred, average='binary')\n",
        "    metrics['recall'] = recall_score(y_true, y_pred, average='binary')\n",
        "    metrics['f1'] = f1_score(y_true, y_pred, average='binary')\n",
        "    metrics['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    # For ROC-AUC and PR-AUC, we need probabilities\n",
        "    # Ensure y_scores are probabilities of the positive class\n",
        "    metrics['roc_auc'] = roc_auc_score(y_true, y_scores)\n",
        "    metrics['pr_auc'] = average_precision_score(y_true, y_scores)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    \"\"\"Evaluate model and return predictions, true labels, losses and metrics.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Get predicted class and probability scores\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            pos_probs = probs[:, 1].cpu().numpy()  # Probability of positive class\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(pos_probs)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(all_labels, all_preds, all_scores)\n",
        "    metrics['loss'] = total_loss / len(loader)\n",
        "\n",
        "    return metrics, all_preds, all_labels, all_scores\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=30):\n",
        "    \"\"\"Train the model and track metrics.\"\"\"\n",
        "    # Initialize lists to store metrics\n",
        "    metrics_df = pd.DataFrame(columns=['epoch', 'training_loss', 'val_loss', 'val_accuracy',\n",
        "                                       'val_balanced_accuracy', 'val_precision', 'val_recall',\n",
        "                                       'val_f1', 'val_mcc', 'val_roc_auc', 'val_pr_auc'])\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    checkpoint_model_path = os.path.join(checkpoint_folder, f\"checkpoint_model_vgg_{date_str}.pth\")\n",
        "    best_model_path = os.path.join(checkpoint_folder, f\"best_model_vgg_{date_str}.pth\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate training loss\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics, _, _, _ = evaluate(model, val_loader, criterion)\n",
        "        val_loss = val_metrics['loss']\n",
        "        val_acc = val_metrics['accuracy']\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Save checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc\n",
        "        }, checkpoint_model_path)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"New best model saved with validation accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
        "              f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, \"\n",
        "              f\"Val Acc: {val_acc:.2f}%, \"\n",
        "              f\"Val F1: {val_metrics['f1']:.4f}, \"\n",
        "              f\"Val ROC-AUC: {val_metrics['roc_auc']:.4f}\")\n",
        "\n",
        "        # Add metrics to dataframe\n",
        "        metrics_df = pd.concat([metrics_df, pd.DataFrame({\n",
        "            'epoch': [epoch + 1],\n",
        "            'training_loss': [train_loss],\n",
        "            'val_loss': [val_loss],\n",
        "            'val_accuracy': [val_metrics['accuracy']],\n",
        "            'val_balanced_accuracy': [val_metrics['balanced_accuracy']],\n",
        "            'val_precision': [val_metrics['precision']],\n",
        "            'val_recall': [val_metrics['recall']],\n",
        "            'val_f1': [val_metrics['f1']],\n",
        "            'val_mcc': [val_metrics['mcc']],\n",
        "            'val_roc_auc': [val_metrics['roc_auc']],\n",
        "            'val_pr_auc': [val_metrics['pr_auc']]\n",
        "        })], ignore_index=True)\n",
        "\n",
        "    # Save metrics to CSV\n",
        "    metrics_csv_path = os.path.join(checkpoint_folder, f\"metrics_{date_str}.csv\")\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"Training metrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Plot and save training curves\n",
        "    plot_training_curves(metrics_df, checkpoint_folder)\n",
        "\n",
        "    # Plot confusion matrix for best model\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    val_metrics, val_preds, val_labels, _ = evaluate(model, val_loader, criterion)\n",
        "    plot_confusion_matrix(val_labels, val_preds, ['Normal', 'Tumor'], checkpoint_folder, \"validation\")\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "def plot_training_curves(metrics_df, save_folder):\n",
        "    \"\"\"Plot and save training curves.\"\"\"\n",
        "    plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # Plot 1: Training vs Validation Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['training_loss'], 'b-', label='Training Loss')\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_loss'], 'r-', label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 2: Validation Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_accuracy'], 'g-')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 3: Validation F1, Precision, Recall\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_f1'], 'c-', label='F1 Score')\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_precision'], 'm-', label='Precision')\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_recall'], 'y-', label='Recall')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Validation F1, Precision, Recall')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 4: Validation ROC-AUC and PR-AUC\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_roc_auc'], 'b-', label='ROC-AUC')\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_pr_auc'], 'r-', label='PR-AUC')\n",
        "    plt.plot(metrics_df['epoch'], metrics_df['val_mcc'], 'g-', label='MCC')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Validation ROC-AUC, PR-AUC, and MCC')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_folder, f\"training_curves_{date_str}.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, save_folder, dataset_name):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {dataset_name.capitalize()} Set')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_folder, f\"confusion_matrix_{dataset_name}_{date_str}.png\"), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "def test_model(model, test_loader, criterion):\n",
        "    \"\"\"Evaluate the model on the test set and visualize results.\"\"\"\n",
        "    print(\"\\nEvaluating model on test set...\")\n",
        "    test_metrics, test_preds, test_labels, test_scores = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    # Print test metrics\n",
        "    print(f\"\\nTest Set Metrics:\")\n",
        "    print(f\"Loss: {test_metrics['loss']:.6f}\")\n",
        "    print(f\"Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {test_metrics['balanced_accuracy']:.4f}\")\n",
        "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
        "    print(f\"MCC: {test_metrics['mcc']:.4f}\")\n",
        "    print(f\"ROC-AUC: {test_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"PR-AUC: {test_metrics['pr_auc']:.4f}\")\n",
        "\n",
        "    # Plot confusion matrix for test set\n",
        "    plot_confusion_matrix(test_labels, test_preds, ['Normal', 'Tumor'], checkpoint_folder, \"test\")\n",
        "\n",
        "    # Save test metrics to CSV\n",
        "    test_metrics_df = pd.DataFrame({metric: [value] for metric, value in test_metrics.items()})\n",
        "    test_metrics_df.to_csv(os.path.join(checkpoint_folder, f\"test_metrics_{date_str}.csv\"), index=False)\n",
        "\n",
        "    return test_metrics\n",
        "\n",
        "# ------------------- Main Training & Testing Routine -------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the model and collect metrics\n",
        "    metrics_df = train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=30)\n",
        "\n",
        "    # Load best model for testing\n",
        "    best_model_path = os.path.join(checkpoint_folder, f\"best_model_vgg_{date_str}.pth\")\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_metrics = test_model(model, test_loader, criterion)\n",
        "\n",
        "    print(f\"\\nTraining and evaluation complete. Results saved to {checkpoint_folder}\")"
      ]
    }
  ]
}