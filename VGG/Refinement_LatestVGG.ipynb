{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Z687laFG-VB6zXr-WsaiUa2NdQoSjR1t",
      "authorship_tag": "ABX9TyMroO4WWJPiyaqNxLxQ0tck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/Refinement_LatestVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_c2vdBuABWl",
        "outputId": "fc427fc4-71d8-4a87-f1b6-b4876c40f9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-7a80aafdbbc0>:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded checkpoint from /content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\n",
            "Results will be saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250218_123021\n",
            "Processing 117 images in folder 'Glaucous_Winged_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Glaucous_Winged_Gull: 100%|██████████| 117/117 [04:28<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 142 images in folder 'Slaty_Backed_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Slaty_Backed_Gull: 100%|██████████| 142/142 [06:40<00:00,  2.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics saved to /content/drive/My Drive/FYP/VGGAnalysis/20250218_123021/statistics.csv\n",
            "Confusion matrix saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250218_123021/confusion_matrix.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1) Define Your Modified VGG Model\n",
        "# (Make sure the parameters match what you used during training)\n",
        "# -------------------------------------------------------------------------\n",
        "class VGG16Modified(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5, hidden_units=[512]):\n",
        "        super(VGG16Modified, self).__init__()\n",
        "        # Load the pretrained VGG16 model\n",
        "        self.vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.vgg.classifier[6].in_features\n",
        "\n",
        "        # Build your custom classifier\n",
        "        classifier_layers = []\n",
        "        for units in hidden_units:\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(num_ftrs, units),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ])\n",
        "            num_ftrs = units\n",
        "        classifier_layers.append(nn.Linear(num_ftrs, 2))  # Binary classification\n",
        "\n",
        "        # Replace the original classifier's final layer\n",
        "        self.vgg.classifier[6] = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2) Load the Trained Checkpoint\n",
        "# -------------------------------------------------------------------------\n",
        "checkpoint_path = \"/content/drive/My Drive/FYP/VGGModel/HQ3Optuna_20250218/latest_checkpoint.pth\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG16Modified(dropout_rate=0.5, hidden_units=[512]).to(device)\n",
        "model.eval()\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"ERROR: The checkpoint file was not found at:\\n  {checkpoint_path}\\nPlease check the path or filename and try again.\")\n",
        "    exit()\n",
        "else:\n",
        "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  print(f\"Successfully loaded checkpoint from {checkpoint_path}\")\n",
        "# -------------------------------------------------------------------------\n",
        "# 3) Define Class Names and Transformations\n",
        "# -------------------------------------------------------------------------\n",
        "# (Ensure that your folder names match these names exactly)\n",
        "class_names = ['Glaucous_Winged_Gull', 'Slaty_Backed_Gull']\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG expects 224x224 input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Load an image and apply the necessary transforms.\n",
        "    Returns a tensor of shape (1, 3, 224, 224) on the chosen device.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4) Grad-CAM Implementation for VGG\n",
        "# -------------------------------------------------------------------------\n",
        "def generate_gradcam(model, image_tensor, target_layer):\n",
        "    \"\"\"\n",
        "    Runs a forward and backward pass on the image_tensor, computes the gradients\n",
        "    on the specified target_layer, and returns the normalized Grad-CAM heatmap,\n",
        "    predicted class index, and prediction confidence.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "    grads = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        features.append(output)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        grads.append(grad_out[0])\n",
        "\n",
        "    # Register hooks on the target layer\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(image_tensor)\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    predicted_class_idx = torch.argmax(probs, dim=1).item()\n",
        "    predicted_confidence = probs[0, predicted_class_idx].item()\n",
        "\n",
        "    # Backward pass: compute gradient for the predicted class\n",
        "    model.zero_grad()\n",
        "    score = outputs[0, predicted_class_idx]\n",
        "    score.backward()\n",
        "\n",
        "    # Extract gradients and feature maps (remove hooks afterwards)\n",
        "    gradient = grads[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "    feature_map = features[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "    forward_handle.remove()\n",
        "    backward_handle.remove()\n",
        "\n",
        "    # Compute the weights and the weighted combination of feature maps\n",
        "    weights = np.mean(gradient, axis=(1, 2))\n",
        "    cam = np.zeros(feature_map.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * feature_map[i, :, :]\n",
        "\n",
        "    # Apply ReLU and normalize the CAM\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (image_tensor.shape[3], image_tensor.shape[2]))\n",
        "    cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam) + 1e-8)\n",
        "\n",
        "    return cam, predicted_class_idx, predicted_confidence\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5) Utility Functions to Save Visualizations & Statistics\n",
        "# -------------------------------------------------------------------------\n",
        "def save_visualization(image_path, cam, predicted_class, confidence, true_class, save_path):\n",
        "    \"\"\"\n",
        "    Creates an overlay of the Grad-CAM heatmap on the original image with text annotations\n",
        "    (including true class, predicted class, correctness, and confidence) and saves it.\n",
        "    \"\"\"\n",
        "    original_img = Image.open(image_path).resize((224, 224), Image.LANCZOS)\n",
        "    original_np = np.array(original_img)\n",
        "\n",
        "    # Create heatmap from the CAM\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Blend heatmap with original image\n",
        "    overlay = np.clip(0.5 * original_np + 0.5 * heatmap, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Prepare text annotations\n",
        "    pred_label = class_names[predicted_class]\n",
        "    correct = (pred_label == true_class)\n",
        "    confidence_text = f\"{confidence*100:.2f}%\"\n",
        "    result_text = f\"True: {true_class} | Pred: {pred_label} | Conf: {confidence_text} | {'Correct' if correct else 'Wrong'}\"\n",
        "\n",
        "    # Add text to the image using OpenCV (convert to BGR for cv2.putText)\n",
        "    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
        "    cv2.putText(\n",
        "        overlay_bgr,\n",
        "        result_text,\n",
        "        (10, 25),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.6,\n",
        "        (0, 255, 0) if correct else (0, 0, 255),\n",
        "        2,\n",
        "        cv2.LINE_AA\n",
        "    )\n",
        "    overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(overlay_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def save_statistics_csv(stat_list, csv_path):\n",
        "    \"\"\"\n",
        "    Save a list of dictionaries (statistics for each image) into a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(stat_list)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Statistics saved to {csv_path}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 6) Process the Dataset Folder and Generate Grad-CAM Visualizations\n",
        "# -------------------------------------------------------------------------\n",
        "def process_dataset(dataset_path, output_base, delete_wrong=True):\n",
        "    \"\"\"\n",
        "    Processes images stored in subfolders (each subfolder name is taken as the true class),\n",
        "    generates Grad-CAM visualizations, saves the output images (organized into 'correct' and\n",
        "    'wrong' folders per class), logs prediction statistics, generates a confusion matrix,\n",
        "    and optionally deletes wrongly predicted images.\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    if not dataset_path.exists():\n",
        "        print(f\"ERROR: Dataset path not found: {dataset_path}\")\n",
        "        return\n",
        "\n",
        "    # Create an output directory with a timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = Path(output_base) / timestamp\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Results will be saved to: {output_dir}\")\n",
        "\n",
        "    stats_list = []\n",
        "\n",
        "    # Process each subfolder (each corresponding to a true class)\n",
        "    for subfolder in sorted(dataset_path.iterdir()):\n",
        "        if not subfolder.is_dir():\n",
        "            continue\n",
        "\n",
        "        true_class = subfolder.name\n",
        "        if true_class not in class_names:\n",
        "            print(f\"Skipping folder '{true_class}' as it is not in class_names\")\n",
        "            continue\n",
        "\n",
        "        # Create output subdirectories for correct and wrong predictions\n",
        "        out_class_dir = output_dir / true_class\n",
        "        correct_dir = out_class_dir / \"correct\"\n",
        "        wrong_dir = out_class_dir / \"wrong\"\n",
        "        correct_dir.mkdir(parents=True, exist_ok=True)\n",
        "        wrong_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process image files (supports jpg, jpeg, png)\n",
        "        image_files = list(subfolder.glob(\"*.jpg\")) + list(subfolder.glob(\"*.jpeg\")) + list(subfolder.glob(\"*.png\"))\n",
        "        print(f\"Processing {len(image_files)} images in folder '{true_class}'...\")\n",
        "\n",
        "        # Use the last convolutional layer from VGG for Grad-CAM\n",
        "        target_layer = model.vgg.features[-1]\n",
        "\n",
        "        for image_path in tqdm(image_files, desc=f\"Processing {true_class}\"):\n",
        "            try:\n",
        "                # Preprocess image and generate Grad-CAM\n",
        "                image_tensor = preprocess_image(image_path)\n",
        "                cam, predicted_class_idx, predicted_confidence = generate_gradcam(model, image_tensor, target_layer)\n",
        "                predicted_label = class_names[predicted_class_idx]\n",
        "                is_correct = (predicted_label == true_class)\n",
        "\n",
        "                # Choose the save directory based on whether the prediction is correct\n",
        "                save_subdir = correct_dir if is_correct else wrong_dir\n",
        "                save_filename = f\"{image_path.stem}_gradcam.png\"\n",
        "                save_path = str(save_subdir / save_filename)\n",
        "\n",
        "                # Save the visualization\n",
        "                save_visualization(str(image_path), cam, predicted_class_idx, predicted_confidence, true_class, save_path)\n",
        "\n",
        "                # Log the statistics for this image\n",
        "                stats_list.append({\n",
        "                    \"file\": str(image_path),\n",
        "                    \"true_class\": true_class,\n",
        "                    \"predicted_class\": predicted_label,\n",
        "                    \"confidence\": predicted_confidence,\n",
        "                    \"correct\": is_correct,\n",
        "                    \"output_file\": save_path\n",
        "                })\n",
        "\n",
        "                # If the prediction is wrong and deletion is enabled, remove the original image\n",
        "                if (not is_correct) and delete_wrong:\n",
        "                    os.remove(str(image_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Save statistics CSV file\n",
        "    csv_path = output_dir / \"statistics.csv\"\n",
        "    save_statistics_csv(stats_list, csv_path)\n",
        "\n",
        "    # Generate and save the confusion matrix\n",
        "    try:\n",
        "        df = pd.DataFrame(stats_list)\n",
        "        if not df.empty:\n",
        "            confusion = pd.crosstab(df['true_class'], df['predicted_class'], rownames=['True'], colnames=['Predicted'])\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "            plt.title(\"Confusion Matrix\")\n",
        "            cm_path = output_dir / \"confusion_matrix.png\"\n",
        "            plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Confusion matrix saved to: {cm_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating confusion matrix: {e}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 7) Main Execution: Set Your Dataset and Output Folders\n",
        "# -------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the parent folder containing two class subfolders\n",
        "    dataset_path = \"/content/drive/My Drive/FYP/Black Background/\"\n",
        "\n",
        "    # Specify the base output directory (can be on Google Drive or local)\n",
        "    output_base = \"/content/drive/My Drive/FYP/VGGAnalysis\"\n",
        "\n",
        "    # Set delete_wrong=True to permanently remove wrongly predicted images from the source folder\n",
        "    process_dataset(dataset_path, output_base, delete_wrong=True)\n"
      ]
    }
  ]
}