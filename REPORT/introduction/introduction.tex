%\documentclass[12pt]{article}
%\usepackage{amsmath}
%\usepackage{graphicx}
%\usepackage{hyperref}
%\usepackage{enumitem}


\section*{Introduction}

Accurate
\cite{source3}
 species identification is a key starting point for scientific research and conservation efforts. Determining whether two populations can be consistently distinguished based on morphological traits is essential for establishing taxonomic boundaries and designing appropriate conservation strategies. Among birds, gulls (\textit{Laridae}) present a particularly challenging case for identification due to their recent evolutionary divergence and subtle morphological differences. As noted by ornithologists:

\begin{quote}
    ``Gulls can be a challenging group of birds to identify. To the untrained eye, they all look alike, yet, at the same time, in the case of the large gulls, one could say that no two birds look the same!'' \cite{ayyash2024}.
\end{quote}

This project addresses the complex task of fine-grained classification between two closely related gull species: the Slaty-backed Gull and the Glaucous-winged Gull. These species, found primarily in eastern Russia and the Pacific Coast of the USA, display subtle and overlapping physical characteristics. The wing and wingtip patterns—particularly the colour, intensity, and pattern of the primary feathers—are crucial diagnostic features for identification, yet they exhibit considerable variation within each species.

Deep learning approaches offer promising solutions to this taxonomic challenge through their ability to automatically learn discriminative features from large datasets. Fine-grained image classification (FGIC), which focuses on identifying subtle differences between subclasses within the same category, has advanced rapidly over the past decade with the development of sophisticated deep neural network architectures \cite{karpathy2015}. Current approaches to FGIC can be broadly categorized into two frameworks: intensely supervised learning, which requires detailed annotations of discriminative parts, and weakly supervised learning, which achieves comparable or superior results using only image-level labels \cite{zhou2016}.

For species identification specifically, convolutional neural networks (CNNs) such as ResNet, Inception, and DenseNet have demonstrated exceptional capabilities, with recent studies achieving accuracy rates exceeding 97\% in bird species classification tasks \cite{he2016}. These architectures automatically learn hierarchical feature representations—from low-level edges and textures to high-level semantic concepts—that capture the subtle morphological differences between closely related species \cite{simonyan2014}. Modern approaches further enhance classification performance through attention mechanisms that help models focus on discriminative regions without explicit part annotations and multi-network learning strategies that capture complementary visual information at different scales \cite{vaswani2017}.

Unlike traditional machine learning methods that rely on hand-engineered features, deep neural networks can detect complex patterns in high-dimensional data, making them well-suited for fine-grained visual classification tasks. However, these models often function as ``black boxes,'' providing little insight into their decision-making processes—a critical limitation in scientific applications where understanding the reasoning behind classifications is as important as the classifications themselves.

This project therefore focuses not only on developing high-accuracy classification models but also on implementing robust interpretability techniques to visualize and understand which morphological features drive model decisions. By bridging computer vision and ornithological expertise, this work aims to contribute both to the technological advancement of interpretable fine-grained classification and to the biological understanding of gull taxonomy.

\section*{Motivation}

The classification of gulls presents multiple challenges that make traditional identification methods problematic and inconsistent. These difficulties stem from several interrelated factors:

First, Glaucous-winged Gulls exhibit unusual levels of variation compared to other gull species. As noted in ornithological literature:

\begin{quote}
    ``The amount of variation here is disturbing because it is unmatched by any other gull species, and more so because it is not completely understood'' \cite{ornithology2023}.
\end{quote}

This variability extends to wingtip patterns, which are critical for species identification but inconsistent within populations.

Second, multiple confounding factors complicate identification:
\begin{itemize}
    \item \textbf{Hybridization:} Both species can interbreed in overlapping ranges, creating intermediate forms.
    \item \textbf{Age-related variations:} Juvenile and immature gulls display less distinct patterns than adults.
    \item \textbf{Environmental effects:} Feather bleaching from sun exposure, contamination, and wear can alter appearance.
    \item \textbf{Seasonal moulting:} Gulls undergo plumage changes throughout the year, affecting diagnostic features.
    \item \textbf{Viewing conditions:} Lighting, angle, and distance significantly impact observed coloration.
\end{itemize}

These complications can make manual classification both time-consuming and subjective. While traditional taxonomic guides provide detailed descriptions of distinguishing features \cite{taxonomicguide2023}, the subtle nature of these differences often leads to inconsistent identifications.

Deep learning offers a powerful alternative by automatically learning distinctive features from large datasets. However, the ``black box'' nature of most neural networks limits their usefulness in scientific contexts where understanding the basis for classifications is crucial. This project therefore emphasizes interpretability alongside accuracy, ensuring that model decisions can be validated against expert knowledge and potentially yield new insights into the morphological basis of species differentiation.

By focusing specifically on adult in-flight images where wingtip patterns are most visible, this project addresses the core taxonomic question while minimizing confounding variables. The resulting interpretable classification system aims to provide both a practical identification tool and a scientific instrument for exploring morphological variation within and between these closely related species.
%
%\section*{Aims and Objectives}
%
%\subsection*{Primary Aims}
%\begin{enumerate}
%    \item To develop high-performance deep learning models capable of distinguishing between Slaty-backed and Glaucous-winged Gulls based on their morphological characteristics.
%    \item To implement robust interpretability techniques that reveal which features influence model decisions, allowing validation against ornithological expertise.
%    \item To analyze whether consistent morphological differences exist between the two species and identify key discriminative features.
%\end{enumerate}
%
%\subsection*{Specific Objectives}
%The project will be carried out in four phases:
%\begin{enumerate}[label=Phase~\arabic*:]
%    \item Model Development and Evaluation
%        \begin{itemize}
%            \item Curate a high-quality dataset of adult in-flight gull images with clearly visible diagnostic features.
%            \item Implement and compare multiple deep learning architectures (CNNs, Vision Transformers) for fine-grained classification.
%            \item Optimize model performance through appropriate regularization techniques, data augmentation, and hyperparameter tuning.
%            \item Evaluate models using appropriate metrics (accuracy, precision, recall, F1-score) on carefully constructed test sets.
%        \end{itemize}
%    \item Interpretability Implementation
%        \begin{itemize}
%            \item Implement Gradient-weighted Class Activation Mapping (Grad-CAM) for convolutional architectures.
%            \item Develop or adapt interpretability techniques suitable for Vision Transformers.
%            \item Visualize regions of images that most influence classification decisions.
%            \item Compare model focus areas with known taxonomic features described in ornithological literature.
%        \end{itemize}
%    \item Feature Analysis
%        \begin{itemize}
%            \item Perform quantitative analysis of image regions highlighted by interpretability techniques.
%            \item Compare intensity, texture, and pattern characteristics between species.
%            \item Identify statistically significant morphological differences between correctly classified specimens.
%        \end{itemize}
%    \item Refinement and Validation
%        \begin{itemize}
%            \item Refine models and interpretability methods based on insights from feature analysis.
%            \item Validate findings against expert ornithological knowledge.
%            \item Document limitations, edge cases, and areas for future research.
%        \end{itemize}
%\end{enumerate}



% Add references manually or link to a .bib file once available

%\end{document}
