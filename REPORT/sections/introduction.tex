%! Author = Aravindh P
%! Date = 26-03-2025

\chapter{Introduction}

Identifying species accurately is a key starting point for all scientific research and conservation. Determining whether two populations can be consistently separated based on their morphology—distinct physical traits—is essential for establishing whether they represent different species. Morphological characteristics, such as plumage patterns and body structures, serve as critical indicators in taxonomic classification.

``Gulls can be a challenging group of birds to identify. To the untrained eye, they all look alike, yet, at the same time, in the case of the large gulls, one could say that no two birds look the same!'' \cite{gull_identification}

Gulls (Laridae), which occur across the Arctic Ocean, have evolved quite recently. Many populations within this group are poorly differentiated, leading to uncertainty about how to identify them and, in turn, their taxonomic status. For many gulls, it remains unclear whether populations are part of the same species or actually different species.

Wingtip features are particularly important for gull identification. Correspondingly, differences in these features are often utilized to determine the taxonomic status of populations. However, most existing methodologies rely on manual, visual inspection of wingtip features.

This project focuses on using deep learning to classify two closely related gull species: the Slaty-backed Gull and the Glaucous-winged Gull. These species, found primarily in eastern Russia and the Pacific Coast of the USA, exhibit subtle and overlapping morphological differences that make them difficult to distinguish. This classification task presents a valuable use case for developing and refining architectures and interpretability methods tailored to challenging fine-grained classification problems.

Accurate species identification is a fundamental requirement in scientific research, ecology, and conservation. Determining whether two populations can be reliably distinguished based on their morphological traits—such as plumage patterns or body structures—enables biologists to clarify taxonomic boundaries and design appropriate conservation measures. Gulls (Laridae) illustrate this complexity: while they occur globally, many closely related populations show subtle physical differences, making manual identification challenging. As one expert notes, ``Gulls can be a challenging group of birds to identify. To the untrained eye, they all look alike, yet, at the same time, in the case of the large gulls, one could say that no two birds look the same!'' \cite{gull_identification}. These nuanced variations extend to key features like wingtips, which are often used to classify species, but require meticulous human observation.

Among gulls, the Slaty-backed Gull and the Glaucous-winged Gull exemplify these fine-grained distinctions. They inhabit overlapping regions—primarily eastern Russia and the Pacific Coast of the USA—and share overlapping morphological traits that complicate traditional identification. Several factors exacerbate this difficulty. Seasonal and age-related changes in plumage can mask species-specific markings; juvenile or moulting gulls often display less distinct patterns, and environmental effects (e.g., bleaching or lighting conditions) can alter observed coloration \cite{gull_variation}. These issues, along with possible hybridization zones, can make manual classification subjective and time-consuming.

In this project, deep learning offers a powerful alternative to manual methods. Unlike traditional machine learning approaches that rely on hand-engineered features, deep neural networks can automatically learn high-level representations crucial for distinguishing visually similar classes—exactly the challenge posed by fine-grained gull identification. Convolutional Neural Networks (CNNs) excel in capturing localized patterns that differentiate species, and modern architectures like Vision Transformers (ViTs) leverage self-attention to highlight nuanced, global features across an image. For difficult tasks such as telling apart Slaty-backed and Glaucous-winged Gulls, these models can focus on subtle wingtip markings, plumage hues, and shape cues that are easily overlooked by the human eye.

However, interpretability remains a key issue in deep learning. Although these models can match or exceed human-level accuracy on many benchmarks, they often function as ``black boxes,'' obscuring which image regions drive classification decisions. In a domain like ecology—where understanding why a model predicts one species versus another can be as valuable as the prediction itself—methods such as Gradient-weighted Class Activation Mapping (Grad-CAM) and Saliency Maps become invaluable. They reveal how the network ``sees'' particular morphological traits, enabling domain experts to validate whether the model's focus aligns with biologically meaningful features.

Accordingly, this project aims to develop and refine deep learning architectures for gull classification while also emphasizing model interpretability. By curating a dataset specifically composed of adult, in-flight gull images, we mitigate age- and posture-related confusions and allow the networks to concentrate on distinctive wingtip features. The ultimate goal is not just to achieve high accuracy in differentiating the Slaty-backed Gull from the Glaucous-winged Gull, but also to produce transparent models that help biologists confirm (or even discover) the morphological signals that truly separate these species. The findings can potentially contribute to broader ecological questions, such as how gull populations vary regionally and whether certain morphological traits correspond to particular evolutionary or environmental pressures.
