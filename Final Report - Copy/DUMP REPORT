\section{Model Performance}

\subsection{Well-Performing Models}

% Table 4: Validation and Test Accuracy Comparison
\begin{table}[htbp]
    \centering
    \caption{Validation and Test Accuracy Comparison}
    \label{tab:val_test_comparison}
    \begin{tabular}{lccc}
    \toprule
    \textbf{Model} & \textbf{Val. Acc. (\%)} & \textbf{Test Acc. (\%)} \\
    \midrule
    VGG-16  & 97.37 & 95.74 \\
    ViT & 94.74 & 93.62 \\
    Inception v3 & 97.80 & 91.49  \\
    ResNet50 & 96.04 & 82.98 \\
    EnhancedViT & 94.52 & 95.74  \\
    InterpretableViT & 94.74 & 95.74 \\
    \bottomrule
    \end{tabular}
\end{table}


% % Option 1: Reduce font size and column spacing
% \begin{table}[htbp]
%     \centering
%     \caption{Comprehensive Model Performance Metrics}
%     \label{tab:combined_performance}
%     \footnotesize
%     \setlength{\tabcolsep}{3pt}
%     \begin{tabular}{lccccccc}
%     \toprule
%     \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{Test (\%)}} & \multicolumn{3}{c}{\textbf{Glaucous Winged}} & \multicolumn{3}{c}{\textbf{Slaty Backed}} \\
%     \cmidrule(lr){3-5} \cmidrule(lr){6-8}
%     & & \textbf{Prec (\%)} & \textbf{Rec (\%)} & \textbf{F1 (\%)} & \textbf{Prec (\%)} & \textbf{Rec (\%)} & \textbf{F1 (\%)} \\
%     \midrule
%     VGG-16  & 95.74 & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
%     ViT  & 93.62 & 100.00 & 78.57 & 88.00 & 91.67 & 100.00 & 95.65 \\
%     Inception v3 & 91.49 & 77.78 & 100.00 & 87.50 & 100.00 & 87.88 & 93.55 \\
%     ResNet50 & 82.98 & 66.67 & 85.71 & 75.00 & 93.10 & 81.82 & 87.10 \\
%     EnhancedViT & 95.74 & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
%     InterpretableViT & 95.74 & 92.86 & 92.86 & 92.86 & 96.97 & 96.97 & 96.97 \\
%     \bottomrule
%     \end{tabular}
% \end{table}


\begin{table}[htbp]
    \centering
    \caption{Comprehensive Model Performance Metrics on Test Dataset}
    \label{tab:combined_performance}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcccccc}
    \toprule
    \multirow{2}{*}{\textbf{Model}} & \multicolumn{3}{c}{\textbf{Glaucous Winged}} & \multicolumn{3}{c}{\textbf{Slaty Backed}} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7}
    & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1 (\%)} & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1 (\%)} \\
    \midrule
    VGG-16 & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
    ViT & 100.00 & 78.57 & 88.00 & 91.67 & 100.00 & 95.65 \\
    Inception v3 & 77.78 & 100.00 & 87.50 & 100.00 & 87.88 & 93.55 \\
    ResNet50 & 66.67 & 85.71 & 75.00 & 93.10 & 81.82 & 87.10 \\
    EnhancedViT & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
    InterpretableViT & 92.86 & 92.86 & 92.86 & 96.97 & 96.97 & 96.97 \\
    \bottomrule
    \end{tabular}%
    }
\end{table}



% Option 3
% \begin{table}[htbp]
%     \centering
%     \caption{Comprehensive Model Performance Metrics}
%     \label{tab:combined_performance}
%     \begin{tabular}{lccccccc}
%     \toprule
%     \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{Test Acc. (\%)}} & \multicolumn{3}{c}{\textbf{Glaucous Winged}} & \multicolumn{3}{c}{\textbf{Slaty Backed}} \\
%     \cmidrule(lr){3-5} \cmidrule(lr){6-8}
%     & & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1 (\%)} & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1 (\%)} \\
%     \midrule
%     VGG-16 Modified & 95.74 & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
%     Vision Transformer & 93.62 & 100.00 & 78.57 & 88.00 & 91.67 & 100.00 & 95.65 \\
%     Inception v3 & 91.49 & 77.78 & 100.00 & 87.50 & 100.00 & 87.88 & 93.55 \\
%     ResNet50 & 82.98 & 66.67 & 85.71 & 75.00 & 93.10 & 81.82 & 87.10 \\
%     EnhancedViT & 95.74 & 87.50 & 100.00 & 93.33 & 100.00 & 93.94 & 96.88 \\
%     InterpretableViT & 95.74 & 92.86 & 92.86 & 92.86 & 96.97 & 96.97 & 96.97 \\
%     \bottomrule
%     \end{tabular}
% \end{table}


% Table 3: Confusion Matrix Summary
\begin{table}[htbp]
    \centering
    \caption{Confusion Matrix Summary}
    \label{tab:confusion_matrix}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Model} & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} \\
    \midrule
    VGG-16 Modified & 14 & 0 & 2 & 31 \\
    Vision Transformer & 11 & 3 & 0 & 33 \\
    Inception v3 & 14 & 0 & 4 & 29 \\
    ResNet50 & 12 & 2 & 6 & 27 \\
    EnhancedViT & 14 & 0 & 2 & 31 \\
    InterpretableViT & 13 & 1 & 1 & 32 \\
    \bottomrule
    \end{tabular}
    \begin{flushleft}
    \footnotesize
    TP = True Positives (Glaucous Winged Gull correctly classified)\\
    FN = False Negatives (Glaucous Winged Gull misclassified)\\
    FP = False Positives (Slaty Backed Gull misclassified)\\
    TN = True Negatives (Slaty Backed Gull correctly classified)
    \end{flushleft}
\end{table}


\subsection{Earlier Model Trials}
\begin{table}[htbp]
  \centering
  \caption{Validation and Test Accuracy for Initial Models with earlier Datasets}
  \label{tab:earlier_trials}
  \begin{tabular}{lccc}
    \toprule
    \textbf{Model} & \textbf{Dataset} & \textbf{Validation Acc.\,(\%)} & \textbf{Test Acc.\,(\%)} \\
    \midrule
    ResNet50 & Stage 1 & 48.94 & - \\
    ResNet50 & Stage 2 & 57.81 & - \\
    Custom CNN & Stage 2 & 70.58 & 58.82 \\
    Improved Custom CNN & Stage 2 & 80.39 & 64.70 \\
    DenseNet-121 (Transfer Learning) & Stage 2 & 94.94 & 80.49 \\
    Custom Neural Network & Stage 2 & 94.01 & 77.42 \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Model Interpretability}

% === VGG-16 Interpretability ===
\subsection{VGG-16 Grad-CAM Examples}
\begin{figure}[htbp]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.45\linewidth]{images/interpretability/vgg/bird1.jpg} &
    \includegraphics[width=0.45\linewidth]{images/interpretability/vgg/bird2.jpg} \\[0.5em]
    \includegraphics[width=0.45\linewidth]{images/interpretability/vgg/bird3.jpg} &
    \includegraphics[width=0.45\linewidth]{images/interpretability/vgg/bird4.jpg}
  \end{tabular}
  \caption{Representative Grad-CAM heatmaps for VGG-16 across four bird instances.}
  \label{fig:vgg16_gradcam}
\end{figure}

% % === ViT Interpretability ===
% \subsection{Vision Transformer Attention Maps}
% \begin{figure}[htbp]
%   \centering
%   \begin{tabular}{cc}
%     \includegraphics[width=0.45\linewidth]{images/interpretability/vit/bird1.png} &
%     \includegraphics[width=0.45\linewidth]{images/interpretability/vit/bird2.png} \\[0.5em]
%     \includegraphics[width=0.45\linewidth]{images/interpretability/vit/bird3.png} &
%     \includegraphics[width=0.45\linewidth]{images/interpretability/vit/bird4.png}
%   \end{tabular}
%   \caption{Attention‐based saliency maps for the Vision Transformer on the same four examples.}
%   \label{fig:vit_attention}
% \end{figure}

% % === Side-by-Side Comparison ===
% \subsection{Side-by-Side Comparison}
% \begin{figure}[htbp]
%   \centering
%   \begin{subfigure}[b]{0.48\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/interpretability/vgg/019_gradcam.png}
%     \caption{VGG-16 Grad-CAM}
%     \label{fig:cmp_vgg}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.48\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{images/interpretability/vit/019_attmap.png}
%     \caption{ViT Attention Map}
%     \label{fig:cmp_vit}
%   \end{subfigure}
%   \caption{Comparison of interpretability outputs for a single test image.}
%   \label{fig:interpretability_comparison}
% \end{figure}

\section{Model Interpretability} % Example section

\begin{figure}[htbp]
    \centering
    \begin{tabular}{cccccc}
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird1.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird2.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird3.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird4.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird5.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird6.jpg} \\
        
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird7.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird8.jpg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird9.jpeg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird10.jpeg} &
        \includegraphics[width=0.15\textwidth]{images/interpretability/vgg/bird11.jpeg} \\
    \end{tabular}
    \caption{Bird interpretation visualizations.}
    \label{fig:bird-interpretability}
\end{figure}


\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.13\textwidth}
        \includegraphics[height=3cm]{images/interpretability/vgg/bird1.jpg}
    \end{subfigure}
    \begin{subfigure}[b]{0.13\textwidth}
        \includegraphics[height=3cm]{images/interpretability/vgg/bird2.jpg}
    \end{subfigure}
    \begin{subfigure}[b]{0.13\textwidth}
        \includegraphics[height=3cm]{images/interpretability/vgg/bird3.jpg}
    \end{subfigure}
    \begin{subfigure}[b]{0.13\textwidth}
        \includegraphics[height=3cm]{images/interpretability/vgg/bird4.jpg}
    \end{subfigure}
    % Add more images as needed
    \caption{Collage of images.}
    \label{fig:collage}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{multicols}{6}
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird1.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird2.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird3.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird4.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird5.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird6.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird7.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird8.jpg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird9.jpeg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird10.jpeg}
        
        \includegraphics[width=\linewidth]{images/interpretability/vgg/bird11.jpeg}
    \end{multicols}
    \caption{Collage of images.}
    \label{fig:collage}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird1.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird10.jpeg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird11.jpeg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird12.jpeg}
        \caption{}
    \end{subfigure}
    
    \vspace{0.3em}
    
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird2.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird3.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird4.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird5.jpg}
        \caption{}
    \end{subfigure}
    
    \vspace{0.3em}
    
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird6.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird7.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird8.jpg}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.22\textwidth}
        \includegraphics[width=\textwidth]{images/interpretability/vgg/bird9.jpeg}
        \caption{}
    \end{subfigure}
    \caption{Bird interpretation visualizations.}
    \label{fig:bird-interpretability}
\end{figure}






















% \begin{figure}[htbp] % Placement options for the figure environment
%     \centering % Centers the figure content
    
%     % \begin{subfigure}[b]{0.48\textwidth} % Subfigure 1 (adjust width as needed)
%     %     \centering
%     %     \includegraphics[width=\textwidth]{images/interpretability/vgg/019_gradcam.png} % Replace with your image file path
%     %     \caption{VGG-16 Interpretability Map} % Caption for the first subfigure
%     %     \label{sfig:interp_vgg} % Label for the first subfigure
%     % \end{subfigure}
%     % \hfill % Automatically spaces the subfigures horizontally
%     % \begin{subfigure}[b]{0.48\textwidth} % Subfigure 2 (adjust width as needed)
%     %     \centering
%     %     \includegraphics[width=\textwidth]{images/interpretability/vit/019_gradcam.png} % Replace with your image file path
%     %     \caption{ViT Interpretability Map} % Caption for the second subfigure
%     %     \label{sfig:interp_vit} % Label for the second subfigure
%     % \end{subfigure}
    
%     \caption{Comparison of Interpretability Visualizations for VGG-16 and ViT models.} % Overall figure caption
%     \label{fig:interpretability_maps} % Overall figure label for cross-referencing
% \end{figure}

% Figure \ref{fig:interpretability_maps} illustrates the regions identified as most salient by different models for a sample image. Subfigure \ref{sfig:interp_vgg} shows the result for VGG-16, while Subfigure \ref{sfig:interp_vit} shows the result for ViT.


% \subsection{Overfitting Analysis of the VGG-16 Model}

% \subsection{Overfitting Prevention and Analysis in the VGG-16 Model}

% Model overfitting represents a critical challenge in deep learning applications, particularly in medical image classification where generalizability is paramount. This section presents an in-depth analysis of how the VGG-16 architecture was optimized to prevent overfitting in our COVID-19 classification task, with a specific focus on the implementation and effectiveness of early stopping.

% \subsubsection{Early Stopping Implementation}

% Early stopping was implemented as a key regularization technique to prevent overfitting. This method monitors validation metrics during training and halts the process when validation performance begins to deteriorate, even if training performance continues to improve. Our implementation included:

% \begin{itemize}
%     \item Patience factor of 5 epochs, allowing the model to continue training through minor fluctuations
%     \item Monitoring of validation loss as the primary metric for stopping decisions
%     \item Checkpoint saving to retain the best-performing model state based on validation accuracy
% \end{itemize}

% \subsubsection{Comparative Analysis: With vs. Without Early Stopping}

% Figure~\ref{fig:early_stopping_comparison} illustrates the training dynamics of two identical VGG-16 models: one with early stopping enabled and one allowed to train for the full 30 epochs regardless of validation performance.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\textwidth]{images/early_stopping_comparison.png}
%     \caption{Comparison of training and validation metrics for models with and without early stopping. (a) Loss curves showing divergence after epoch 6 in the non-early-stopped model. (b) Accuracy progression demonstrating stability in the early-stopped model versus potential degradation in validation accuracy in the non-early-stopped model.}
%     \label{fig:early_stopping_comparison}
% \end{figure}

% The model without early stopping exhibited classic signs of overfitting after approximately the 6th epoch:

% \begin{itemize}
%     \item Training loss continued to decrease asymptotically toward zero (reaching as low as 0.000001 by epoch 11)
%     \item Validation loss began to fluctuate and increase inconsistently (from 0.060114 in epoch 11 to values as high as 0.300291 in epoch 8)
%     \item Growing discrepancy between training and validation loss
% \end{itemize}

% By contrast, the model with early stopping terminated training at epoch 6, where:

% \begin{itemize}
%     \item Best validation loss of 0.018944 was achieved
%     \item Validation accuracy peaked at 99.12\%
%     \item Training was halted before validation metrics could deteriorate
% \end{itemize}

% Table~\ref{tab:early_stopping_metrics} provides a quantitative comparison of the two approaches.

% \begin{table}[htbp]
% \centering
% \caption{Performance Comparison: Models With and Without Early Stopping}
% \label{tab:early_stopping_metrics}
% \begin{tabular}{lcc}
% \hline
% \textbf{Metric} & \textbf{With Early Stopping} & \textbf{Without Early Stopping} \\
% \hline
% Best Validation Accuracy & 99.12\% & 98.68\% \\
% Best Validation F1 Score & 0.9949 & 0.9921 \\
% Best Validation ROC-AUC & 0.9994 & 0.9997 \\
% Final Training Loss & 0.099987 & 0.000001 \\
% Best Validation Loss & 0.018944 & 0.032870 \\
% Training Epochs Required & 6 & 11 \\
% Test Accuracy & [TO BE ADDED] & [TO BE ADDED] \\
% \hline
% \end{tabular}
% \end{table}

% \subsubsection{Visualization of Overfitting Patterns}

% Figure~\ref{fig:overfitting_indicators} presents a detailed visualization of overfitting indicators across training epochs for both models.

% % \begin{figure}[htbp]
% %     \centering
% %     \includegraphics[width=0.85\textwidth]{images/overfitting_indicators.png}
% %     \caption{Indicators of overfitting observed throughout training. (a) Train-validation loss gap widening after epoch 6 in the non-early-stopped model. (b) Validation performance stability in the early-stopped model versus fluctuations in the non-early-stopped model. The gray vertical line indicates the early stopping point.}
% %     \label{fig:overfitting_indicators}
% % \end{figure}

% A key observation is the validation loss pattern in the non-early-stopped model. Despite achieving high validation accuracy (98.68\%), the validation loss showed inconsistency and occasional spikes, suggesting that the model was becoming overly confident in some predictions while making more significant errors on others—a classic sign of overfitting.

% \subsubsection{Early Stopping Effectiveness}

% Early stopping proved highly effective in our context for several reasons:

% \begin{enumerate}
%     \item \textbf{Optimal Model Selection}: The technique successfully identified the epoch (epoch 6) where the model achieved optimal generalization, with validation loss at 0.018944 and validation accuracy at 99.12\%.
    
%     \item \textbf{Computational Efficiency}: Training was terminated after only 6 epochs instead of the full 30, representing an 80\% reduction in computational resources without sacrificing performance.
    
%     \item \textbf{Preventing Memorization}: The early-stopped model was prevented from memorizing training data, as evidenced by the moderate final training loss (0.099987) compared to the near-zero training loss (0.000001) in the non-early-stopped model.
    
%     \item \textbf{Generalization}: The validation metrics at the stopping point (accuracy: 99.12\%, F1: 0.9949, ROC-AUC: 0.9994) indicate excellent generalization capabilities.
% \end{enumerate}

% \subsubsection{Statistical Stability Analysis}

% Figure~\ref{fig:metric_stability} illustrates the statistical stability of model performance across different validation metrics.

% % \begin{figure}[htbp]
% %     \centering
% %     \includegraphics[width=0.85\textwidth]{images/metric_stability.png}
% %     \caption{Statistical stability of validation metrics across training epochs. Note the increased variability after the early stopping point (indicated by vertical dashed line) in the non-early-stopped model.}
% %     \label{fig:metric_stability}
% % \end{figure}

% The early-stopped model demonstrated more consistent performance across all metrics, with validation F1-score (0.9949) and ROC-AUC (0.9994) closely aligned with accuracy measurements. This alignment suggests that the model maintains balanced performance across different classes and decision thresholds.

% \subsubsection{Evidence of Generalization}

% Multiple indicators support the conclusion that the early-stopped VGG-16 model successfully generalized without overfitting:

% \begin{itemize}
%     \item \textbf{Validation-Test Alignment}: The small difference between validation accuracy (99.12\%) and test accuracy [TO BE ADDED] indicates consistent performance on unseen data.
    
%     \item \textbf{Moderate Training Loss}: The training loss at stopping point (0.099987) remains non-trivial, suggesting the model learned general patterns rather than memorizing specific examples.
    
%     \item \textbf{High ROC-AUC Value}: The validation ROC-AUC of 0.9994 demonstrates excellent discriminative capability across different operating thresholds.
    
%     \item \textbf{F1 Score Consistency}: The high F1 score (0.9949) indicates balanced precision and recall, suggesting the model performs well across all classes without bias toward the majority class.
    
%     \item \textbf{Grad-CAM Verification}: Visual inspection of Grad-CAM activation maps confirms the model focuses on biologically-relevant features rather than background or artifacts.
% \end{itemize}

% \subsection{Conclusion on Model Robustness}

% Early stopping proved to be an effective regularization technique for our VGG-16 model, producing an optimal model with superior generalization capacity. By halting training at epoch 6, we achieved:

% \begin{enumerate}
%     \item Prevention of overfitting as evidenced by stable validation metrics
%     \item Computational efficiency through reduced training time
%     \item Optimal model selection with peak validation performance (99.12\% accuracy)
%     \item Balanced performance across all evaluation metrics
% \end{enumerate}

% The comparative analysis between early-stopped and non-early-stopped models clearly demonstrates the value of this technique in developing robust deep learning models for medical image classification. The early-stopped VGG-16 model represents an optimal balance between fitting to the training data and maintaining generalization capabilities, making it suitable for real-world clinical applications where performance on unseen data is critical.







% The proposed model demonstrates strong generalization capabilities with no significant indication of overfitting. As shown in Fig.~\ref{fig:training_curves}, validation metrics remain stable or improve throughout training, with validation accuracy increasing from 81.17\% to 95.45\% over 20 epochs. While training loss decreases to near-zero ($2.57 \times 10^{-4}$), validation performance continues to improve, reaching a balanced accuracy of 0.9084 and Matthews Correlation Coefficient (MCC) of 0.8304 in the final epochs.

% The consistent improvement in validation metrics, particularly ROC-AUC (0.9888) and Average Precision (0.9979), suggests the model is learning generalizable patterns rather than memorizing training data. The simultaneous convergence of multiple validation metrics (accuracy, balanced accuracy, MCC) after epoch 14 further supports this conclusion. These results indicate the model architecture and regularization techniques effectively prevent overfitting on this classification task.

% To assess whether the VGG-16 (fine-tuned) model was overfitting, its performance was compared across the training, validation, and test sets. Table~\ref{tab:model_accuracy} shows that the validation accuracy (94.5\%) and test accuracy (93.8\%) are closely matched, with only a 0.7\% difference, indicating minimal overfitting.

% % Furthermore, the training and validation loss curves (Figure~\ref{fig:vgg_loss_curves}) demonstrate that the model's validation loss did not diverge or increase significantly relative to the training loss, which would be expected if overfitting was occurring. Instead, both loss curves plateaued at similar values.

% % \begin{figure}[htbp]
% %     \centering
% %     \includegraphics[width=0.7\textwidth]{images/vgg_loss_curves.png} % Replace with your actual plot file
% %     \caption{Training and validation loss curves for VGG-16, showing minimal gap and no sign of overfitting.}
% %     \label{fig:vgg_loss_curves}
% % \end{figure}

% Finally, the performance on the unseen test set confirms that the model generalizes well to new data. Therefore, there is strong evidence that the VGG-16 model is not overfitting.

% \textbf{Summary of anti-overfitting evidence:}
% \begin{itemize}
%     \item Validation and test accuracy are nearly identical.
%     \item Loss curves for training and validation align closely without divergence.
%     \item High performance is maintained on the unseen test set.
%     \item Visual inspection of Grad-CAM maps shows that the model focuses on biologically-relevant features, reducing the likelihood of memorizing spurious correlations.
% \end{itemize}
