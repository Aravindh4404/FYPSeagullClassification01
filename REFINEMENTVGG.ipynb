{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1paTYhNX2p-dy7UEx1PrHVsbDbjHqFVxp",
      "authorship_tag": "ABX9TyOONjF5qRRCPsG4g3ydDYYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/REFINEMENTVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1) Define the VGG16Modified Class (as per your training)\n",
        "# -------------------------------------------------------------------------\n",
        "class VGG16Modified(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16Modified, self).__init__()\n",
        "        from torchvision.models import VGG16_Weights\n",
        "        self.vgg = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.vgg.classifier[6].in_features\n",
        "        self.vgg.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, 2)  # Binary classification (2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2) Load Model Checkpoint\n",
        "# -------------------------------------------------------------------------\n",
        "checkpoint_path = \"/content/drive/My Drive/FYP/VGGModel/HQ3latst_20250216/checkpoint_model_vgg_20250216.pth\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG16Modified().to(device)\n",
        "model.eval()\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"ERROR: The checkpoint file was not found at:\\n  {checkpoint_path}\\nPlease check the path or filename and try again.\")\n",
        "    exit()\n",
        "else:\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print(f\"Successfully loaded checkpoint from {checkpoint_path}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 3) Define Class Names and Transformations\n",
        "# -------------------------------------------------------------------------\n",
        "# IMPORTANT: Ensure that the folder names in your dataset match these class names.\n",
        "class_names = ['Glaucous_Winged_Gull', 'Slaty_Backed_Gull']\n",
        "# (If needed, update the names to exactly match your folder names.)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG expects 224x224 input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4) Grad-CAM Implementation\n",
        "# -------------------------------------------------------------------------\n",
        "def generate_gradcam(model, image_tensor, target_layer):\n",
        "    \"\"\"\n",
        "    Generates Grad-CAM for a given image and model.\n",
        "    Returns:\n",
        "      cam (normalized 2D numpy array),\n",
        "      predicted_class_idx (int),\n",
        "      predicted_confidence (float)  # new\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "    grads = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        features.append(output)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        grads.append(grad_out[0])\n",
        "\n",
        "    # Register hooks on the target convolutional layer\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(image_tensor)\n",
        "    # Compute softmax to get confidence\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    predicted_class_idx = torch.argmax(probs, dim=1).item()\n",
        "    predicted_confidence = probs[0, predicted_class_idx].item()  # get confidence for predicted class\n",
        "\n",
        "    # Backward pass for the predicted class\n",
        "    model.zero_grad()\n",
        "    class_score = outputs[0, predicted_class_idx]\n",
        "    class_score.backward()\n",
        "\n",
        "    # Extract the gradients and the feature maps\n",
        "    gradient = grads[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "    feature_map = features[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "\n",
        "    # Remove hooks\n",
        "    forward_handle.remove()\n",
        "    backward_handle.remove()\n",
        "\n",
        "    # Compute the weights: global-average pooling of the gradients\n",
        "    weights = np.mean(gradient, axis=(1, 2))  # shape: (C,)\n",
        "\n",
        "    # Generate CAM as a weighted combination of feature maps\n",
        "    cam = np.zeros(feature_map.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * feature_map[i, :, :]\n",
        "\n",
        "    # Apply ReLU and normalize the CAM\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (image_tensor.shape[3], image_tensor.shape[2]))\n",
        "    cam -= np.min(cam)\n",
        "    cam /= (cam.max() + 1e-9)\n",
        "\n",
        "    return cam, predicted_class_idx, predicted_confidence\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5) Utility Functions\n",
        "# -------------------------------------------------------------------------\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Loads an image and applies transformations.\n",
        "    Returns a tensor of shape (1, 3, 224, 224) on the specified device.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "def save_visualization(image_path, cam, predicted_class, confidence, true_class, save_path):\n",
        "    \"\"\"\n",
        "    Creates an overlay of the Grad-CAM heatmap on the original image,\n",
        "    adds text annotations (true class, predicted class, correctness, confidence), and\n",
        "    saves the result to 'save_path'.\n",
        "    \"\"\"\n",
        "    # Load and resize original image\n",
        "    original_img = Image.open(image_path).resize((224, 224), Image.LANCZOS)\n",
        "    original_np = np.array(original_img)\n",
        "\n",
        "    # Create heatmap from CAM\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Blend heatmap with the original image\n",
        "    overlay = np.clip(0.5 * original_np + 0.5 * heatmap, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Prepare text to overlay\n",
        "    pred_label = class_names[predicted_class]\n",
        "    correct = (predicted_class == class_names.index(true_class))\n",
        "    confidence_text = f\"{confidence*100:.2f}%\"\n",
        "    result_text = f\"True: {true_class} | Pred: {pred_label} | Conf: {confidence_text} | {'Correct' if correct else 'Wrong'}\"\n",
        "\n",
        "    # Add text overlay using cv2.putText; convert image to BGR for OpenCV\n",
        "    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
        "    cv2.putText(\n",
        "        overlay_bgr,\n",
        "        result_text,\n",
        "        (10, 25),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.6,\n",
        "        (0, 255, 0) if correct else (0, 0, 255),\n",
        "        2,\n",
        "        cv2.LINE_AA\n",
        "    )\n",
        "    # Convert back to RGB for saving\n",
        "    overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Save the image\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(overlay_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def save_statistics_csv(stat_list, csv_path):\n",
        "    \"\"\"\n",
        "    Saves the list of statistics (one dict per image) as a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(stat_list)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Statistics saved to {csv_path}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 6) Process Dataset Folder with Two Classes and Save Results\n",
        "# -------------------------------------------------------------------------\n",
        "def process_dataset(dataset_path, output_base, delete_wrong=True):\n",
        "    \"\"\"\n",
        "    Processes images stored in subfolders (each subfolder name is taken as the true class)\n",
        "    and generates Grad-CAM visualizations with text overlays.\n",
        "\n",
        "    The output is saved to Google Drive under 'output_base/TIMESTAMP/'.\n",
        "    The folder structure created is:\n",
        "       TIMESTAMP/\n",
        "           <true_class>/\n",
        "               correct/   (images that were correctly classified)\n",
        "               wrong/     (images that were misclassified)\n",
        "\n",
        "    Also collects statistics (true class, predicted class, file name, confidence, etc.) for later review.\n",
        "\n",
        "    Parameters:\n",
        "      dataset_path (str/Path): The directory containing two subfolders (each named after a class).\n",
        "      output_base (str/Path) : Base folder to store the output results.\n",
        "      delete_wrong (bool)    : If True, the code will delete the original file when it is wrongly predicted.\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    if not dataset_path.exists():\n",
        "        print(f\"ERROR: Dataset path not found: {dataset_path}\")\n",
        "        return\n",
        "\n",
        "    # Create an output directory with a timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = Path(output_base) / timestamp\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Results will be saved to: {output_dir}\")\n",
        "\n",
        "    # Prepare statistics list\n",
        "    stats_list = []\n",
        "\n",
        "    # Process each subfolder (each is a true class)\n",
        "    for subfolder in sorted(dataset_path.iterdir()):\n",
        "        if not subfolder.is_dir():\n",
        "            continue\n",
        "        true_class = subfolder.name\n",
        "        if true_class not in class_names:\n",
        "            print(f\"Skipping folder '{true_class}' as it is not in class_names\")\n",
        "            continue\n",
        "\n",
        "        # Create output subfolders for this true class (correct & wrong)\n",
        "        out_class_dir = output_dir / true_class\n",
        "        correct_dir = out_class_dir / \"correct\"\n",
        "        wrong_dir = out_class_dir / \"wrong\"\n",
        "        correct_dir.mkdir(parents=True, exist_ok=True)\n",
        "        wrong_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process each image file in this class folder\n",
        "        # (support jpg, jpeg, png; you can extend below)\n",
        "        image_files = list(subfolder.glob(\"*.[jJ][pP][gG]\")) + \\\n",
        "                      list(subfolder.glob(\"*.[jJ][pP][eE][gG]\")) + \\\n",
        "                      list(subfolder.glob(\"*.[pP][nN][gG]\"))\n",
        "        print(f\"Processing {len(image_files)} images in folder '{true_class}'...\")\n",
        "\n",
        "        # Use the last convolutional layer of VGG for Grad-CAM\n",
        "        target_layer = model.vgg.features[-1]\n",
        "\n",
        "        for image_path in tqdm(image_files, desc=f\"Processing {true_class}\"):\n",
        "            try:\n",
        "                # Preprocess image\n",
        "                image_tensor = preprocess_image(image_path)\n",
        "\n",
        "                # Generate Grad-CAM and get prediction + confidence\n",
        "                cam, predicted_class_idx, predicted_confidence = generate_gradcam(model, image_tensor, target_layer)\n",
        "                predicted_label = class_names[predicted_class_idx]\n",
        "                is_correct = (predicted_label == true_class)\n",
        "\n",
        "                # Determine save directory based on correctness\n",
        "                save_subdir = correct_dir if is_correct else wrong_dir\n",
        "                save_filename = f\"{image_path.stem}_gradcam.png\"\n",
        "                save_path = str(save_subdir / save_filename)\n",
        "\n",
        "                # Save the visualization (with overlay text)\n",
        "                save_visualization(str(image_path), cam, predicted_class_idx, predicted_confidence, true_class, save_path)\n",
        "\n",
        "                # Append to statistics\n",
        "                stats_list.append({\n",
        "                    \"file\": str(image_path),\n",
        "                    \"true_class\": true_class,\n",
        "                    \"predicted_class\": predicted_label,\n",
        "                    \"confidence\": predicted_confidence,\n",
        "                    \"correct\": is_correct,\n",
        "                    \"output_file\": save_path\n",
        "                })\n",
        "\n",
        "                # If wrong, delete the original image from the dataset\n",
        "                if (not is_correct) and delete_wrong:\n",
        "                    # Caution: This permanently removes the file from disk\n",
        "                    os.remove(str(image_path))\n",
        "                    # If you prefer to move it instead of deleting, use:\n",
        "                    # import shutil\n",
        "                    # shutil.move(str(image_path), str(wrong_dir / image_path.name))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Save statistics as CSV in the output directory\n",
        "    csv_path = output_dir / \"statistics.csv\"\n",
        "    save_statistics_csv(stats_list, csv_path)\n",
        "\n",
        "    # Optionally, generate and save a confusion matrix\n",
        "    try:\n",
        "        df = pd.DataFrame(stats_list)\n",
        "        if not df.empty:\n",
        "            confusion = pd.crosstab(df['true_class'], df['predicted_class'], rownames=['True'], colnames=['Predicted'])\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "            plt.title(\"Confusion Matrix\")\n",
        "            cm_path = output_dir / \"confusion_matrix.png\"\n",
        "            plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Confusion matrix saved to: {cm_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating confusion matrix: {e}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 7) Main Execution\n",
        "# -------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the parent folder containing your two class subfolders.\n",
        "    dataset_path = \"/content/drive/My Drive/FYP/Black Background/\"\n",
        "\n",
        "    # Specify the base output directory (on Google Drive or local).\n",
        "    output_base = \"/content/drive/My Drive/FYP/VGGAnalysis\"\n",
        "\n",
        "    # Set delete_wrong=True if you want to permanently delete wrongly predicted images.\n",
        "    process_dataset(dataset_path, output_base, delete_wrong=True)\n"
      ],
      "metadata": {
        "id": "Vdr5cu57Wsog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5b13ff-2f07-4439-80ed-074e5b8ed1d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 142MB/s]\n",
            "<ipython-input-1-87564d99d425>:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded checkpoint from /content/drive/My Drive/FYP/VGGModel/HQ3latst_20250216/checkpoint_model_vgg_20250216.pth\n",
            "Results will be saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250218_040548\n",
            "Processing 124 images in folder 'Glaucous_Winged_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Glaucous_Winged_Gull: 100%|██████████| 124/124 [00:26<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 143 images in folder 'Slaty_Backed_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Slaty_Backed_Gull: 100%|██████████| 143/143 [01:41<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics saved to /content/drive/My Drive/FYP/VGGAnalysis/20250218_040548/statistics.csv\n",
            "Confusion matrix saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250218_040548/confusion_matrix.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2Ef83-oU2Fq",
        "outputId": "df1224f3-2b39-4137-e4da-d12229b3abc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c430202279e6>:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded checkpoint from /content/drive/My Drive/FYP/VGGModel/HQ3latst_20250216/checkpoint_model_vgg_20250216.pth\n",
            "Results will be saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250216_153814\n",
            "Processing 116 images in folder 'Glaucous_Winged_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Glaucous_Winged_Gull: 100%|██████████| 116/116 [04:42<00:00,  2.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 97 images in folder 'Slaty_Backed_Gull'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Slaty_Backed_Gull: 100%|██████████| 97/97 [05:33<00:00,  3.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics saved to /content/drive/My Drive/FYP/VGGAnalysis/20250216_153814/statistics.csv\n",
            "Confusion matrix saved to: /content/drive/My Drive/FYP/VGGAnalysis/20250216_153814/confusion_matrix.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1) Define the VGG16Modified Class (as per your training)\n",
        "# -------------------------------------------------------------------------\n",
        "class VGG16Modified(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16Modified, self).__init__()\n",
        "        from torchvision.models import VGG16_Weights\n",
        "        self.vgg = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.vgg.classifier[6].in_features\n",
        "        self.vgg.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, 2)  # Binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2) Load Model Checkpoint\n",
        "# -------------------------------------------------------------------------\n",
        "checkpoint_path = \"/content/drive/My Drive/FYP/VGGModel/HQ3latst_20250216/checkpoint_model_vgg_20250216.pth\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG16Modified().to(device)\n",
        "model.eval()\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"ERROR: The checkpoint file was not found at:\\n  {checkpoint_path}\\nPlease check the path or filename and try again.\")\n",
        "    exit()\n",
        "else:\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print(f\"Successfully loaded checkpoint from {checkpoint_path}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 3) Define Class Names and Transformations\n",
        "# -------------------------------------------------------------------------\n",
        "# IMPORTANT: Ensure that the folder names in your dataset match these class names.\n",
        "class_names = ['Glaucous_Winged_Gull', 'Slaty_Backed_Gull']\n",
        "# (If needed, update the names to exactly match your folder names.)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # VGG expects 224x224 input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4) Grad-CAM Implementation\n",
        "# -------------------------------------------------------------------------\n",
        "def generate_gradcam(model, image_tensor, target_layer):\n",
        "    \"\"\"\n",
        "    Generates Grad-CAM for a given image and model.\n",
        "    Returns:\n",
        "      cam (normalized 2D numpy array),\n",
        "      predicted_class_idx (int)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "    grads = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        features.append(output)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        grads.append(grad_out[0])\n",
        "\n",
        "    # Register hooks on the target convolutional layer\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(image_tensor)\n",
        "    predicted_class_idx = outputs.argmax(dim=1).item()\n",
        "\n",
        "    # Backward pass for the predicted class\n",
        "    model.zero_grad()\n",
        "    class_score = outputs[0, predicted_class_idx]\n",
        "    class_score.backward()\n",
        "\n",
        "    # Extract the gradients and the feature maps\n",
        "    gradient = grads[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "    feature_map = features[0].detach().cpu().numpy()[0]  # shape: (C, H, W)\n",
        "\n",
        "    # Remove hooks\n",
        "    forward_handle.remove()\n",
        "    backward_handle.remove()\n",
        "\n",
        "    # Compute the weights: global-average pooling of the gradients\n",
        "    weights = np.mean(gradient, axis=(1, 2))  # shape: (C,)\n",
        "\n",
        "    # Generate CAM as a weighted combination of feature maps\n",
        "    cam = np.zeros(feature_map.shape[1:], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * feature_map[i, :, :]\n",
        "\n",
        "    # Apply ReLU and normalize the CAM\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam, (image_tensor.shape[3], image_tensor.shape[2]))\n",
        "    cam -= np.min(cam)\n",
        "    cam /= (cam.max() + 1e-9)\n",
        "\n",
        "    return cam, predicted_class_idx\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5) Utility Functions\n",
        "# -------------------------------------------------------------------------\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"\n",
        "    Loads an image and applies transformations.\n",
        "    Returns a tensor of shape (1, 3, 224, 224) on the specified device.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "def save_visualization(image_path, cam, predicted_class, true_class, save_path):\n",
        "    \"\"\"\n",
        "    Creates an overlay of the Grad-CAM heatmap on the original image,\n",
        "    adds text annotations (true class, predicted class, correctness), and\n",
        "    saves the result to 'save_path'.\n",
        "    \"\"\"\n",
        "    # Load and resize original image\n",
        "    original_img = Image.open(image_path).resize((224, 224), Image.LANCZOS)\n",
        "    original_np = np.array(original_img)\n",
        "\n",
        "    # Create heatmap from CAM\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Blend heatmap with the original image\n",
        "    overlay = np.clip(0.5 * original_np + 0.5 * heatmap, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Prepare text to overlay\n",
        "    pred_label = class_names[predicted_class]\n",
        "    correct = (predicted_class == class_names.index(true_class))\n",
        "    result_text = f\"True: {true_class} | Pred: {pred_label} | {'Correct' if correct else 'Wrong'}\"\n",
        "\n",
        "    # Add text overlay using cv2.putText; convert image to BGR for OpenCV\n",
        "    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
        "    cv2.putText(overlay_bgr, result_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7, (0, 255, 0) if correct else (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    # Convert back to RGB for saving\n",
        "    overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Save the image\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(overlay_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def save_statistics_csv(stat_list, csv_path):\n",
        "    \"\"\"\n",
        "    Saves the list of statistics (one dict per image) as a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(stat_list)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Statistics saved to {csv_path}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 6) Process Dataset Folder with Two Classes and Save Results\n",
        "# -------------------------------------------------------------------------\n",
        "def process_dataset(dataset_path, output_base):\n",
        "    \"\"\"\n",
        "    Processes images stored in subfolders (each subfolder name is taken as the true class)\n",
        "    and generates Grad-CAM visualizations with text overlays.\n",
        "\n",
        "    The output is saved to Google Drive under 'output_base/TIMESTAMP/'.\n",
        "    The folder structure created is:\n",
        "       TIMESTAMP/\n",
        "           <true_class>/\n",
        "               correct/   (images that were correctly classified)\n",
        "               wrong/     (images that were misclassified)\n",
        "\n",
        "    Also collects statistics (true class, predicted class, file name, etc.) for later review.\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    if not dataset_path.exists():\n",
        "        print(f\"ERROR: Dataset path not found: {dataset_path}\")\n",
        "        return\n",
        "\n",
        "    # Create an output directory with a timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = Path(output_base) / timestamp\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Results will be saved to: {output_dir}\")\n",
        "\n",
        "    # Prepare statistics list\n",
        "    stats_list = []\n",
        "\n",
        "    # Process each subfolder (each is a true class)\n",
        "    for subfolder in sorted(dataset_path.iterdir()):\n",
        "        if not subfolder.is_dir():\n",
        "            continue\n",
        "        true_class = subfolder.name\n",
        "        if true_class not in class_names:\n",
        "            print(f\"Skipping folder '{true_class}' as it is not in class_names\")\n",
        "            continue\n",
        "\n",
        "        # Create output subfolders for this true class (correct & wrong)\n",
        "        out_class_dir = output_dir / true_class\n",
        "        correct_dir = out_class_dir / \"correct\"\n",
        "        wrong_dir = out_class_dir / \"wrong\"\n",
        "        correct_dir.mkdir(parents=True, exist_ok=True)\n",
        "        wrong_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process each image file in this class folder\n",
        "        image_files = list(subfolder.glob(\"*.[jJ][pP][gG]\")) + list(subfolder.glob(\"*.[pP][nN][gG]\"))\n",
        "        print(f\"Processing {len(image_files)} images in folder '{true_class}'...\")\n",
        "\n",
        "        # Use the last convolutional layer of VGG for Grad-CAM\n",
        "        target_layer = model.vgg.features[-1]\n",
        "\n",
        "        for image_path in tqdm(image_files, desc=f\"Processing {true_class}\"):\n",
        "            try:\n",
        "                # Preprocess image\n",
        "                image_tensor = preprocess_image(image_path)\n",
        "\n",
        "                # Generate Grad-CAM and get prediction\n",
        "                cam, predicted_class_idx = generate_gradcam(model, image_tensor, target_layer)\n",
        "                predicted_label = class_names[predicted_class_idx]\n",
        "                is_correct = (predicted_label == true_class)\n",
        "\n",
        "                # Determine save directory based on correctness\n",
        "                save_subdir = correct_dir if is_correct else wrong_dir\n",
        "                save_filename = f\"{image_path.stem}_gradcam.png\"\n",
        "                save_path = str(save_subdir / save_filename)\n",
        "\n",
        "                # Save the visualization (with overlay text)\n",
        "                save_visualization(str(image_path), cam, predicted_class_idx, true_class, save_path)\n",
        "\n",
        "                # Append to statistics\n",
        "                stats_list.append({\n",
        "                    \"file\": str(image_path),\n",
        "                    \"true_class\": true_class,\n",
        "                    \"predicted_class\": predicted_label,\n",
        "                    \"correct\": is_correct,\n",
        "                    \"output_file\": save_path\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Save statistics as CSV in the output directory\n",
        "    csv_path = output_dir / \"statistics.csv\"\n",
        "    save_statistics_csv(stats_list, csv_path)\n",
        "\n",
        "    # Optionally, generate and save a confusion matrix\n",
        "    try:\n",
        "        df = pd.DataFrame(stats_list)\n",
        "        if not df.empty:\n",
        "            confusion = pd.crosstab(df['true_class'], df['predicted_class'], rownames=['True'], colnames=['Predicted'])\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "            plt.title(\"Confusion Matrix\")\n",
        "            cm_path = output_dir / \"confusion_matrix.png\"\n",
        "            plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Confusion matrix saved to: {cm_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating confusion matrix: {e}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 7) Main Execution\n",
        "# -------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the parent folder containing your two class subfolders.\n",
        "    dataset_path = \"/content/drive/My Drive/FYP/Entire Bird Segment/\"\n",
        "    # Specify the base output directory (on Google Drive)\n",
        "    output_base = \"/content/drive/My Drive/FYP/VGGAnalysis\"\n",
        "    process_dataset(dataset_path, output_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMOmfXGWI-K",
        "outputId": "0035d474-0e87-41cd-a448-fcc444bedcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}