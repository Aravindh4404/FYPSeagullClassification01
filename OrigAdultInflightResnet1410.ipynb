{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/OrigAdultInflightResnet1410.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access/save files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Define paths to training data\n",
        "train_data_root = \"/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/train\"\n",
        "test_data_root = \"/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/test\"\n",
        "IMAGE_SHAPE = (224, 224)  # Image size for ResNet50\n",
        "BATCH_SIZE = 32  # Adjust batch size as per the dataset size\n",
        "EPOCHS = 20  # Set the number of epochs\n",
        "\n",
        "# Output paths for saving models and class indices\n",
        "MODEL_SAVE_PATH = '/content/drive/My Drive/FYP/MODELS/best_resnet50_model.h5'\n",
        "FINAL_MODEL_SAVE_PATH = '/content/drive/My Drive/FYP/MODELS/resnet50_final_model.h5'\n",
        "CLASS_INDICES_SAVE_PATH = '/content/drive/My Drive/FYP/class_indices.npy'\n",
        "\n",
        "# Create ImageDataGenerator for training and validation with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize the pixel values\n",
        "    validation_split=0.3,  # 30% of data used for validation\n",
        "    rotation_range=10,  # Augmentation: rotate images by 10 degrees\n",
        "    zoom_range=0.1,  # Augmentation: zoom in by 10%\n",
        "    horizontal_flip=True  # Augmentation: randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_root,\n",
        "    subset=\"training\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    train_data_root,\n",
        "    subset=\"validation\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Save class indices mapping for future use during testing\n",
        "class_indices = train_generator.class_indices\n",
        "np.save(CLASS_INDICES_SAVE_PATH, class_indices)\n",
        "print(f\"Class indices saved: {class_indices}\")\n",
        "\n",
        "# Load pre-trained ResNet50 model, excluding the top layers\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=IMAGE_SHAPE + (3,))\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global pooling layer\n",
        "x = Dense(1024, activation='relu')(x)  # Fully connected layer with 1024 units\n",
        "predictions = Dense(len(class_indices), activation='softmax')(x)  # Output layer for classification\n",
        "\n",
        "# Define the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the ResNet50 base layers initially (only train new layers)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model compiled successfully.\")\n",
        "\n",
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "# Update model save path to use `.keras` extension\n",
        "MODEL_SAVE_PATH = '/content/drive/My Drive/FYP/MODELS/best_resnet50_model.keras'\n",
        "FINAL_MODEL_SAVE_PATH = '/content/drive/My Drive/FYP/MODELS/resnet50_final_model.keras'\n",
        "\n",
        "# Model checkpoint to save the best model based on validation loss\n",
        "model_checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# List of callbacks\n",
        "callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the final model after training using the `.keras` format\n",
        "model.save(FINAL_MODEL_SAVE_PATH)\n",
        "print(f\"Final model saved at: {FINAL_MODEL_SAVE_PATH}\")\n",
        "\n",
        "# Unfreeze some of the base model layers for fine-tuning\n",
        "for layer in base_model.layers[-20:]:  # Unfreeze the last 20 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile the model with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,  # Fine-tune for a few epochs\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "fine_tuned_model_path = '/content/drive/My Drive/FYP/MODELS/resnet50_fine_tuned_model.h5'\n",
        "model.save(fine_tuned_model_path)\n",
        "print(f\"Fine-tuned model saved at: {fine_tuned_model_path}\")\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // BATCH_SIZE)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpzFFzJ4w6lR",
        "outputId": "abba7165-3146-4ed8-bb2a-9b05c5a1b52a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 176 images belonging to 2 classes.\n",
            "Found 75 images belonging to 2 classes.\n",
            "Class indices saved: {'Glaucous_Winged_Gull': 0, 'Slaty_Backed_Gull': 1}\n",
            "Model compiled successfully.\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.5378 - loss: 1.3154 - val_accuracy: 0.4219 - val_loss: 1.0248\n",
            "Epoch 2/20\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5312 - loss: 0.8491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 731ms/step - accuracy: 0.5312 - loss: 0.8491 - val_accuracy: 0.0000e+00 - val_loss: 1.2134\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 533ms/step - accuracy: 0.4606 - loss: 0.9519 - val_accuracy: 0.4219 - val_loss: 1.0701\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.4062 - loss: 1.0920 - val_accuracy: 1.0000 - val_loss: 0.2076\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.5681 - loss: 0.7576 - val_accuracy: 0.5781 - val_loss: 0.7509\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.5000 - loss: 0.8533 - val_accuracy: 0.0000e+00 - val_loss: 0.9862\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 368ms/step - accuracy: 0.5660 - loss: 0.6838 - val_accuracy: 0.4219 - val_loss: 0.7590\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4688 - loss: 0.6779 - val_accuracy: 0.6364 - val_loss: 0.6717\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 502ms/step - accuracy: 0.5821 - loss: 0.6802 - val_accuracy: 0.4219 - val_loss: 0.7561\n",
            "Final model saved at: /content/drive/My Drive/FYP/MODELS/resnet50_final_model.keras\n",
            "Epoch 1/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - accuracy: 0.4989 - loss: 1.0796 - val_accuracy: 0.4219 - val_loss: 0.9664\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 345ms/step - accuracy: 0.6875 - loss: 0.5893 - val_accuracy: 1.0000 - val_loss: 0.2574\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 405ms/step - accuracy: 0.6373 - loss: 0.6103 - val_accuracy: 0.4219 - val_loss: 0.9118\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5625 - loss: 0.6171 - val_accuracy: 1.0000 - val_loss: 0.2901\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.6844 - loss: 0.5956 - val_accuracy: 0.4219 - val_loss: 0.8813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model saved at: /content/drive/My Drive/FYP/MODELS/resnet50_fine_tuned_model.h5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step - accuracy: 0.2812 - loss: 1.1431\n",
            "Validation Loss: 0.9727997779846191\n",
            "Validation Accuracy: 0.421875\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOo0nkvhTTIRQAQiGq24Eqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}