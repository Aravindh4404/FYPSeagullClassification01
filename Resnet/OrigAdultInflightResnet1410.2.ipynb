{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/OrigAdultInflightResnet1410.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access/save files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Define paths to training data\n",
        "train_data_root = \"/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/train\"\n",
        "IMAGE_SHAPE = (224, 224)  # Image size for ResNet50\n",
        "BATCH_SIZE = 32  # Larger batch size for faster training\n",
        "EPOCHS = 20  # Initial number of epochs\n",
        "\n",
        "# Output paths for saving models and other results\n",
        "MODEL_SAVE_PATH = '/content/drive/My Drive/FYP/MODELS/best_resnet50_model_v2.keras'\n",
        "CLASS_INDICES_SAVE_PATH = '/content/drive/My Drive/FYP/class_indices_v2.npy'\n",
        "\n",
        "# Create ImageDataGenerator for training and validation with increased augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize the pixel values\n",
        "    validation_split=0.3,  # 30% of data used for validation\n",
        "    rotation_range=20,  # Increase rotation for more variability\n",
        "    zoom_range=0.2,  # Increase zoom for more variability\n",
        "    width_shift_range=0.2,  # Add horizontal shift\n",
        "    height_shift_range=0.2,  # Add vertical shift\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    brightness_range=[0.8, 1.2],  # Vary brightness\n",
        "    horizontal_flip=True  # Randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_root,\n",
        "    subset=\"training\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    train_data_root,\n",
        "    subset=\"validation\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Save class indices mapping for future use\n",
        "class_indices = train_generator.class_indices\n",
        "np.save(CLASS_INDICES_SAVE_PATH, class_indices)\n",
        "print(f\"Class indices saved: {class_indices}\")\n",
        "\n",
        "# Load pre-trained ResNet50 model, excluding the top layers\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=IMAGE_SHAPE + (3,))\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global pooling layer\n",
        "x = Dense(1024, activation='relu')(x)  # Fully connected layer with 1024 units\n",
        "predictions = Dense(len(class_indices), activation='softmax')(x)  # Output layer for classification\n",
        "\n",
        "# Define the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the ResNet50 base layers initially (only train new layers)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model compiled successfully.\")\n",
        "\n",
        "# Early stopping to avoid overfitting, with increased patience\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Model checkpoint to save the best model based on validation accuracy\n",
        "model_checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# List of callbacks\n",
        "callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the final model after training\n",
        "final_model_path = '/content/drive/My Drive/FYP/MODELS/resnet50_final_model_v2.keras'\n",
        "model.save(final_model_path)\n",
        "print(f\"Final model saved at: {final_model_path}\")\n",
        "\n",
        "# Unfreeze more layers for fine-tuning (e.g., last 50 layers)\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile the model with a smaller learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=20,  # Fine-tune for more epochs\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "fine_tuned_model_path = '/content/drive/My Drive/FYP/MODELS/resnet50_fine_tuned_model_v2.keras'\n",
        "model.save(fine_tuned_model_path)\n",
        "print(f\"Fine-tuned model saved at: {fine_tuned_model_path}\")\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // BATCH_SIZE)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpzFFzJ4w6lR",
        "outputId": "3c61df23-be04-4d71-f8bb-cc415ac80948"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 176 images belonging to 2 classes.\n",
            "Found 75 images belonging to 2 classes.\n",
            "Class indices saved: {'Glaucous_Winged_Gull': 0, 'Slaty_Backed_Gull': 1}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Model compiled successfully.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 12s/step - accuracy: 0.5226 - loss: 0.8574 - val_accuracy: 0.5781 - val_loss: 0.7414\n",
            "Epoch 2/20\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6562 - loss: 0.6669"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 733ms/step - accuracy: 0.6562 - loss: 0.6669 - val_accuracy: 0.0000e+00 - val_loss: 1.3114\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4512 - loss: 0.8462 - val_accuracy: 0.5781 - val_loss: 0.6978\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5938 - loss: 0.6860 - val_accuracy: 0.0000e+00 - val_loss: 1.0682\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 865ms/step - accuracy: 0.5026 - loss: 0.7383 - val_accuracy: 0.5781 - val_loss: 0.6851\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.4688 - loss: 0.7309 - val_accuracy: 0.0000e+00 - val_loss: 0.8928\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 889ms/step - accuracy: 0.5208 - loss: 0.7041 - val_accuracy: 0.5625 - val_loss: 0.6839\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.4062 - loss: 0.7203 - val_accuracy: 0.0000e+00 - val_loss: 0.7687\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 404ms/step - accuracy: 0.4843 - loss: 0.6992 - val_accuracy: 0.4844 - val_loss: 0.6950\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.5312 - loss: 0.6907 - val_accuracy: 0.7273 - val_loss: 0.6820\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 437ms/step - accuracy: 0.4458 - loss: 0.6978 - val_accuracy: 0.4219 - val_loss: 0.7083\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 456ms/step - accuracy: 0.4375 - loss: 0.7033 - val_accuracy: 1.0000 - val_loss: 0.6263\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 402ms/step - accuracy: 0.5100 - loss: 0.6958 - val_accuracy: 0.4219 - val_loss: 0.7126\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 896ms/step - accuracy: 0.4375 - loss: 0.7129 - val_accuracy: 1.0000 - val_loss: 0.6053\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 575ms/step - accuracy: 0.5399 - loss: 0.6895 - val_accuracy: 0.4219 - val_loss: 0.7126\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5625 - loss: 0.6899 - val_accuracy: 1.0000 - val_loss: 0.6202\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 400ms/step - accuracy: 0.4632 - loss: 0.7075 - val_accuracy: 0.4219 - val_loss: 0.7078\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5625 - loss: 0.6840 - val_accuracy: 1.0000 - val_loss: 0.6480\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.5341 - loss: 0.6905 - val_accuracy: 0.4219 - val_loss: 0.7056\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4688 - loss: 0.7027 - val_accuracy: 1.0000 - val_loss: 0.6386\n",
            "Final model saved at: /content/drive/My Drive/FYP/MODELS/resnet50_final_model_v2.keras\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.4698 - loss: 0.7222 - val_accuracy: 0.4219 - val_loss: 0.7128\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 0.6878 - val_accuracy: 1.0000 - val_loss: 0.5892\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 454ms/step - accuracy: 0.5537 - loss: 0.6985 - val_accuracy: 0.4219 - val_loss: 0.7216\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 867ms/step - accuracy: 0.5625 - loss: 0.6598 - val_accuracy: 1.0000 - val_loss: 0.5828\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 457ms/step - accuracy: 0.5767 - loss: 0.6805 - val_accuracy: 0.4219 - val_loss: 0.7181\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 917ms/step - accuracy: 0.6875 - loss: 0.6458 - val_accuracy: 1.0000 - val_loss: 0.5743\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 534ms/step - accuracy: 0.5324 - loss: 0.6831 - val_accuracy: 0.4219 - val_loss: 0.7294\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6828 - val_accuracy: 1.0000 - val_loss: 0.5702\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 836ms/step - accuracy: 0.5543 - loss: 0.6882 - val_accuracy: 0.4219 - val_loss: 0.7280\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 808ms/step - accuracy: 0.5625 - loss: 0.6634 - val_accuracy: 1.0000 - val_loss: 0.5554\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 612ms/step - accuracy: 0.6372 - loss: 0.6620 - val_accuracy: 0.4219 - val_loss: 0.7382\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 906ms/step - accuracy: 0.6250 - loss: 0.6541 - val_accuracy: 1.0000 - val_loss: 0.5080\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 469ms/step - accuracy: 0.6440 - loss: 0.6607 - val_accuracy: 0.4219 - val_loss: 0.7608\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 834ms/step - accuracy: 0.7188 - loss: 0.6253 - val_accuracy: 1.0000 - val_loss: 0.4742\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 578ms/step - accuracy: 0.7021 - loss: 0.6523 - val_accuracy: 0.4219 - val_loss: 0.7758\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.6037 - val_accuracy: 1.0000 - val_loss: 0.4579\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 460ms/step - accuracy: 0.6166 - loss: 0.6561 - val_accuracy: 0.4219 - val_loss: 0.8058\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 0.6839 - val_accuracy: 1.0000 - val_loss: 0.4144\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 462ms/step - accuracy: 0.5292 - loss: 0.6669 - val_accuracy: 0.4219 - val_loss: 0.8206\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.6251 - val_accuracy: 1.0000 - val_loss: 0.3877\n",
            "Fine-tuned model saved at: /content/drive/My Drive/FYP/MODELS/resnet50_fine_tuned_model_v2.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695ms/step - accuracy: 0.2812 - loss: 0.9225\n",
            "Validation Loss: 0.8198391199111938\n",
            "Validation Accuracy: 0.421875\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8XDbP2CQC7di9Tev8Fzr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}