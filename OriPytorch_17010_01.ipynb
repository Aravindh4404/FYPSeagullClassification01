{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzyxjbrtG1ki04cfss3YSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/OriPytorch_17010_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-zb0WJtl8av",
        "outputId": "829ae5fa-aeea-44d2-ff06-8580919a4b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/20], Loss: 63.04700061321259\n",
            "Validation Loss: 17.834278958184377, Accuracy: 62.745098039215684%\n",
            "Best model saved with accuracy: 62.7451% at /content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth\n",
            "Epoch [2/20], Loss: 12.80675023588352\n",
            "Validation Loss: 13.918910571507045, Accuracy: 58.8235294117647%\n",
            "Epoch [3/20], Loss: 8.831869990974665\n",
            "Validation Loss: 8.290153094700404, Accuracy: 60.78431372549019%\n",
            "Epoch [4/20], Loss: 5.915653438400182\n",
            "Validation Loss: 2.413027532731316, Accuracy: 68.62745098039215%\n",
            "Best model saved with accuracy: 68.6275% at /content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth\n",
            "Epoch [5/20], Loss: 3.9278940629959105\n",
            "Validation Loss: 4.0254563348633905, Accuracy: 68.62745098039215%\n",
            "Epoch [6/20], Loss: 2.536029438132059\n",
            "Validation Loss: 1.9143593348562717, Accuracy: 76.47058823529412%\n",
            "Best model saved with accuracy: 76.4706% at /content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth\n",
            "Epoch [7/20], Loss: 1.7224658857716713\n",
            "Validation Loss: 1.9089649229177408, Accuracy: 74.50980392156863%\n",
            "Epoch [8/20], Loss: 1.7590152438730002\n",
            "Validation Loss: 1.562737587706319, Accuracy: 80.3921568627451%\n",
            "Best model saved with accuracy: 80.3922% at /content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth\n",
            "Epoch [9/20], Loss: 1.653383904953953\n",
            "Validation Loss: 1.755659758055117, Accuracy: 74.50980392156863%\n",
            "Epoch [10/20], Loss: 1.4063982259482146\n",
            "Validation Loss: 1.089105258030551, Accuracy: 74.50980392156863%\n",
            "Epoch [11/20], Loss: 1.4455568673688686\n",
            "Validation Loss: 1.7026037403515406, Accuracy: 64.70588235294117%\n",
            "Epoch [12/20], Loss: 1.2473092986643224\n",
            "Validation Loss: 1.8451444506645203, Accuracy: 66.66666666666667%\n",
            "Epoch [13/20], Loss: 1.4047360852174462\n",
            "Validation Loss: 0.8961762344198567, Accuracy: 74.50980392156863%\n",
            "Epoch [14/20], Loss: 1.3753321738913655\n",
            "Validation Loss: 1.898469511951719, Accuracy: 76.47058823529412%\n",
            "Epoch [15/20], Loss: 1.4856971716415137\n",
            "Validation Loss: 1.2206821643880434, Accuracy: 68.62745098039215%\n",
            "Epoch [16/20], Loss: 1.0836848889663815\n",
            "Validation Loss: 1.1721332626683372, Accuracy: 74.50980392156863%\n",
            "Epoch [17/20], Loss: 1.4305017587542534\n",
            "Validation Loss: 1.3769710745130266, Accuracy: 66.66666666666667%\n",
            "Epoch [18/20], Loss: 1.0487077152729034\n",
            "Validation Loss: 1.865079973425184, Accuracy: 68.62745098039215%\n",
            "Epoch [19/20], Loss: 1.215036062479485\n",
            "Validation Loss: 1.4874611965247564, Accuracy: 72.54901960784314%\n",
            "Epoch [20/20], Loss: 1.139616301432252\n",
            "Validation Loss: 1.1477030089923315, Accuracy: 76.47058823529412%\n",
            "Test Loss: 2.640970700021301, Test Accuracy: 64.70588235294117%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Mount Google Drive to save and load the model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the folder to save model checkpoints\n",
        "checkpoint_folder = '/content/drive/My Drive/FYP/ModelCheckpoints/'\n",
        "os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "# Improved Data Augmentation for Training Set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),  # Resize images to 300x300\n",
        "    transforms.RandomHorizontalFlip(),  # Random horizontal flip for more data variety\n",
        "    transforms.RandomRotation(15),  # Random rotation by 15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Color jitter for variation\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])\n",
        "\n",
        "# Simple resizing for validation and test sets\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Data preparation: Training, Validation, and Test sets\n",
        "data_path = '/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/train'\n",
        "test_data_path = '/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/test'\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(test_data_path, transform=transform_val_test)\n",
        "\n",
        "# Split the dataset into 80% training and 20% validation\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 8  # Increased batch size for better training stability\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define a more robust CNN model\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        # Convolutional layers with BatchNorm\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = None\n",
        "        self._initialize_fc(input_size)\n",
        "\n",
        "    def _initialize_fc(self, input_size):\n",
        "        \"\"\" Dynamically calculate FC layer size \"\"\"\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.randn(1, *input_size)\n",
        "            dummy_output = self.pool(self.bn1(torch.relu(self.conv1(dummy_input))))\n",
        "            flattened_size = dummy_output.view(1, -1).size(1)\n",
        "            self.fc1 = nn.Linear(flattened_size, 2)  # Assuming binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass with convolution, batch norm, pooling, and dropout\n",
        "        x = self.pool(self.bn1(torch.relu(self.conv1(x))))\n",
        "        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n",
        "        x = self.dropout(x)  # Apply dropout before the final FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the improved model\n",
        "input_size = (3, 300, 300)  # 3 channels, 300x300 images\n",
        "model = ImprovedCNN(input_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Adam with an initial learning rate and a scheduler for decay\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by 10% every 5 epochs\n",
        "\n",
        "# Function to save the best model\n",
        "def save_best_model(model, folder_path, best_val_acc):\n",
        "    model_save_path = os.path.join(folder_path, \"best_model.pth\")\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Best model saved with accuracy: {best_val_acc:.4f}% at {model_save_path}\")\n",
        "\n",
        "# Training loop with best model saving\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20):\n",
        "    model.train()\n",
        "    best_val_acc = 0.0  # Initialize the best validation accuracy\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print the loss per epoch\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "        # Validate the model and check accuracy\n",
        "        val_acc = validate(model, val_loader, criterion)\n",
        "\n",
        "        # Save the model if validation accuracy improves\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            save_best_model(model, checkpoint_folder, best_val_acc)\n",
        "\n",
        "# Validation loop returning accuracy\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Loss: {val_loss/len(loader)}, Accuracy: {accuracy}%')\n",
        "    return accuracy  # Return accuracy to track the best model\n",
        "\n",
        "# Test function to evaluate on the test set\n",
        "def test(model, loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Loss: {test_loss/len(loader)}, Test Accuracy: {accuracy}%')\n",
        "\n",
        "\n",
        "# Train and validate the improved model\n",
        "train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20)\n",
        "\n",
        "# Run the model on the test set\n",
        "test(model, test_loader, criterion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((300, 300)),  # Resize to the size used during training\n",
        "        transforms.ToTensor(),  # Convert the image to a tensor\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image)\n",
        "    image = image.unsqueeze(0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "# Load the saved model\n",
        "def load_model(model, checkpoint_path):\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    print(f\"Model loaded from {checkpoint_path}\")\n",
        "    return model\n",
        "\n",
        "# Predict the class of the specific image\n",
        "def predict_image(model, image_tensor, class_names):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)  # Get the predicted class index\n",
        "\n",
        "    predicted_class_name = class_names[predicted.item()]  # Get the class name based on the index\n",
        "    return predicted_class_name\n",
        "\n",
        "# Path to the specific image\n",
        "image_path = '/content/480 (41).jpeg'\n",
        "# Path to the best saved model\n",
        "best_model_path = '/content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth'\n",
        "\n",
        "# Initialize the model\n",
        "input_size = (3, 300, 300)  # 3 channels, 300x300 images\n",
        "loaded_model = ImprovedCNN(input_size)\n",
        "\n",
        "# Load the best saved model\n",
        "loaded_model = load_model(loaded_model, best_model_path)\n",
        "\n",
        "# Preprocess the specific image\n",
        "image_tensor = preprocess_image(image_path)\n",
        "\n",
        "# Load the dataset to get the class names\n",
        "data_path = '/content/drive/My Drive/FYP/Dataset/Original_Adult_In-flight/train'\n",
        "train_dataset = datasets.ImageFolder(data_path, transform=transform_val_test)\n",
        "\n",
        "# The list of class names\n",
        "class_names = train_dataset.classes  # This will give you a list of class labels\n",
        "\n",
        "# Predict the class\n",
        "predicted_class_name = predict_image(loaded_model, image_tensor, class_names)\n",
        "print(f\"Predicted class: {predicted_class_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls-jR5O9svve",
        "outputId": "f9dfa0f1-b1b4-422d-f039-5a6db0a2591b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from /content/drive/My Drive/FYP/ModelCheckpoints/best_model.pth\n",
            "Predicted class: Slaty_Backed_Gull\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d2798ded4eed>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        }
      ]
    }
  ]
}