{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindh4404/FYPSeagullClassification01/blob/main/VIT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wsvm895wS1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1ab902-4505-4469-aff7-df2bb85b0f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3HgvGOcwDvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bb4d9d-23c4-4e55-9812-ebc71b644413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ooaxSuLwIfT",
        "outputId": "27c6c46c-91c1-4a87-a3d2-c7063e693e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "Train Loss: 0.8411 | Val Loss: 0.8240\n",
            "Val Acc: 48.68% | Val F1: 0.6214\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30\n",
            "Train Loss: 0.8555 | Val Loss: 0.5918\n",
            "Val Acc: 96.71% | Val F1: 0.9807\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30\n",
            "Train Loss: 1.0934 | Val Loss: 0.6759\n",
            "Val Acc: 16.45% | Val F1: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30\n",
            "Train Loss: 0.7404 | Val Loss: 1.2194\n",
            "Val Acc: 88.16% | Val F1: 0.9333\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30\n",
            "Train Loss: 1.5772 | Val Loss: 0.7157\n",
            "Val Acc: 80.92% | Val F1: 0.8816\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30\n",
            "Train Loss: 1.1284 | Val Loss: 0.7066\n",
            "Val Acc: 78.95% | Val F1: 0.8667\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30\n",
            "Train Loss: 0.7935 | Val Loss: 0.7756\n",
            "Val Acc: 26.32% | Val F1: 0.2113\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30\n",
            "Train Loss: 0.8153 | Val Loss: 0.7308\n",
            "Val Acc: 89.47% | Val F1: 0.9398\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30\n",
            "Train Loss: 0.7837 | Val Loss: 0.6537\n",
            "Val Acc: 19.74% | Val F1: 0.0758\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30\n",
            "Train Loss: 0.6992 | Val Loss: 0.6065\n",
            "Val Acc: 88.16% | Val F1: 0.9286\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30\n",
            "Train Loss: 0.6919 | Val Loss: 0.6646\n",
            "Val Acc: 89.47% | Val F1: 0.9385\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30\n",
            "Train Loss: 0.6866 | Val Loss: 0.5586\n",
            "Val Acc: 80.26% | Val F1: 0.8696\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30\n",
            "Train Loss: 0.6266 | Val Loss: 0.7912\n",
            "Val Acc: 88.82% | Val F1: 0.9368\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30\n",
            "Train Loss: 0.6821 | Val Loss: 0.8497\n",
            "Val Acc: 92.76% | Val F1: 0.9579\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30\n",
            "Train Loss: 0.7317 | Val Loss: 0.6529\n",
            "Val Acc: 89.47% | Val F1: 0.9389\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30\n",
            "Train Loss: 0.6415 | Val Loss: 0.6705\n",
            "Val Acc: 53.95% | Val F1: 0.6196\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30\n",
            "Train Loss: 0.6208 | Val Loss: 0.5564\n",
            "Val Acc: 85.53% | Val F1: 0.9068\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30\n",
            "Train Loss: 0.6485 | Val Loss: 0.5515\n",
            "Val Acc: 88.82% | Val F1: 0.9323\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30\n",
            "Train Loss: 0.6015 | Val Loss: 0.5243\n",
            "Val Acc: 74.34% | Val F1: 0.8219\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29be704d02fb>:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import timm\n",
        "from timm.scheduler import CosineLRScheduler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from collections import Counter\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define checkpoint folder\n",
        "date_str = datetime.now().strftime('%Y%m%d')\n",
        "checkpoint_folder = f'/content/drive/My Drive/FYP/VIT2_HQ2_{date_str}/'\n",
        "os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "# Data Augmentation with ImageNet Normalization\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load datasets\n",
        "data_path = '/content/drive/My Drive/FYP/Dataset/HQ2/train'\n",
        "test_data_path = '/content/drive/My Drive/FYP/Dataset/HQ2/test'\n",
        "train_dataset = datasets.ImageFolder(data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(test_data_path, transform=transform_val_test)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Calculate class weights for imbalanced data\n",
        "full_targets = [label for _, label in train_dataset]\n",
        "class_counts = Counter(full_targets)\n",
        "total_samples = len(full_targets)\n",
        "n_classes = 2\n",
        "class_weights = [\n",
        "    total_samples / (n_classes * class_counts[0]),\n",
        "    total_samples / (n_classes * class_counts[1])\n",
        "]\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Data Loaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "# Enhanced ViT Model with Dropout\n",
        "class ViTEnhanced(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(self.vit.num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = ViTEnhanced().to(device)\n",
        "\n",
        "# Loss Function with Label Smoothing and Class Weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.05)\n",
        "num_epochs = 30\n",
        "scheduler = CosineLRScheduler(optimizer, t_initial=num_epochs, warmup_t=5, warmup_lr_init=1e-6)\n",
        "\n",
        "# Mixed Precision Scaler\n",
        "scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / len(loader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
        "    return total_loss/len(loader), accuracy, f1\n",
        "\n",
        "def test_tta(model, loader, n_tta=5):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    tta_trans = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "    ])\n",
        "\n",
        "    unnormalize = transforms.Normalize(\n",
        "        mean=[-m/s for m, s in zip(imagenet_mean, imagenet_std)],\n",
        "        std=[1/s for s in imagenet_std]\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in loader:\n",
        "            inputs = inputs.cpu()\n",
        "            unnormalized = unnormalize(inputs)\n",
        "            batch_preds = []\n",
        "\n",
        "            for _ in range(n_tta):\n",
        "                augmented = torch.stack([tta_trans(transforms.ToPILImage()(img)) for img in unnormalized])\n",
        "                augmented = augmented.to(device)\n",
        "                outputs = model(augmented)\n",
        "                batch_preds.append(outputs.softmax(1))\n",
        "\n",
        "            avg_preds = torch.mean(torch.stack(batch_preds), dim=0)\n",
        "            all_preds.extend(avg_preds.argmax(1).cpu().numpy())\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=30):\n",
        "    best_f1 = 0.0\n",
        "    train_losses, val_losses = [], []\n",
        "    val_accuracies, val_f1s = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast(enabled=torch.cuda.is_available()):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step(epoch + 1)\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "        val_metrics = validate(model, val_loader, criterion)\n",
        "        val_loss, val_acc, val_f1 = val_metrics\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        val_f1s.append(val_f1)\n",
        "\n",
        "        # Save Best Model\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), os.path.join(checkpoint_folder, 'best_model.pth'))\n",
        "\n",
        "        # Save Latest Model\n",
        "        torch.save(model.state_dict(), os.path.join(checkpoint_folder, 'latest_model.pth'))\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "        print(f'Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.4f}\\n')\n",
        "\n",
        "    # Plot metrics\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_accuracies, label='Val Accuracy')\n",
        "    plt.plot(val_f1s, label='Val F1')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Execute Training\n",
        "train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=num_epochs)\n",
        "\n",
        "# Final Evaluation\n",
        "test_preds = test_tta(model, test_loader)\n",
        "test_labels = [label for _, label in test_dataset.samples]\n",
        "test_acc = 100 * accuracy_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds, average='binary')\n",
        "\n",
        "print(f'Final Test Accuracy: {test_acc:.2f}% | F1 Score: {test_f1:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UMUKq2JQiHyRjGuacqhUyBd_gK5BoOhf",
      "authorship_tag": "ABX9TyNGK0IXLWQ8YsVhD+p8A29/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}